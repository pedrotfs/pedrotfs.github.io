AWS Solution Architecture

aws - cloud provider - amazon, netflix...
aplicações escalaveis - backend, sites, servers, etc... infinitos casos de uso
global

Regions

    Regions - us east-1 ...etc - cluster de datacenters - compliance(dados só saem com sua permissão) - proximidade (diminuir latencia) - disponibilidade (tem serviços q não tem em todas regiões) - preço
    Availability Zones - cada região tem vários (min 3, max 6)
        cada um deses é um ou mais datacenters, com conexões, energia e conectividades redundantes (replicas - disponibilidade) - separados, para isolar desastres
    Edge Locations/Points of presence - 400+ em 90+ cidades em 40+ países - conteudo é entregue a usuários finais com latencia menor
    Serviços globais: IAM (identity and access manager) - Route 53 (DNS) - CloudFront (CDN) - WAF (web app firewall)
    maioria de serviços tem escopo de região (EC2 - infra as service, Beanstalk - platform as service, Lambda - function as service, rekognition - software as service)
    
AWS console

    região - escolhe região
    tutoriais - recentemente visitados
    muda muito
    serviços - topo esquerdo - alfabetico ou por categoria - tem busca tb
    global infrastructure - regional services - serviços por região
    
IAM - Identity and Acess Management - Users & Groups

    Global
    conta root criada por padrão - não deve ser usada ou compartilhada - criar usuários - representam pessoas e podem ser agrupadas
    Permissão - documento json policy - descreve o que usuário ou grupo pode fazer - politica do privilegio minimo

    Criar Usuarios
    
        global - impede selecionar região - disponivel global
        
        IAM console - IAM dashboard - Users - Create User
            nome usuario, escolher se em identity center(recomendado) ou IAM user (IAM user é o que cai na certificação)
            se não for para o usuario, deixar autogenerated e pedir para mudar proximo acesso - pode mandar por email
            
            Criar grupo -> escolhe policy
            
            tags podem dar metadados para tudo na aws
            mostra por onde vem a policy, se por usuario ou por grupo
            
        pode criar alias para conta para não ter q usar id - url, tem q ser unico
        
        sign in tem root user e IAM user
        
    Herança de Policy
    
        é possivel herdar de multiplas fontes
        consiste de versão, id, statement (contem sid, efeito(permite ou não) , principal (contem conta, usuario ou role), 
            action ((lista ações que a politica afeta) resource(recurso que ações podem afetar)
            condição (opcional - quando politica tá em efeito))
        * any - em statement any action any resource - resource:* action:* - pode usar como regex tb tipo Get*
        
    IAM MFA
    
        password policy - quanto mais forte, mais seguro - opções como tamanho minimo, tipos de caracter, etc, permitir usuarios IAM de mudar propria senha, forçar mudança em tanto tempo
            prevenção de uso de senha reusada
            
        MFA - multi-factor - preferir
            proteger root e usuarios IAM - usuarios q podem apagar recursos ou mudar configurações
            
        opções - virtual (authy (multiplos devices), google auth(phones)) - 
        universal 2nd factor (U2F) - aparelho proprio
        hardware key fob mfa device
        aws govcloud keyfob (us)
        
    AWS Access Keys, CLI and SDK
    
        Console(password + MFA)
        CommandLine Interface (CLI) (access key) - terminal - tudo começa com aws ex aws s3 les s3://ccp-bucket - alternativa ao console
            aceita scripts - open source - acesso direto a apis publicas de serviços aws
        AWS Software Developer Kit (SDK) (access key) - bibliotecas especificasa linguagem - acesso a serviços aws em linguagens de programação
            embutido em aplicação - muitas linguagens - iot (arduino, embedded c)
        
        access key são geradas pelo console aws - usuarios gerenciam suas chaves - acess key Id ~ username - secret access key ~ password
            criar em users > usuario > security credentials > create access key
            no cli: aws configure > access key > secret > região padrão > 
            ~> aws iam list-users
            
            permissão CLI são as mesmas do console
    
        CloudShell - icone de terminal do lado da busca do console aws - nem toda região tem? - alternativa a aws cli
        
        IAM roles para serviços
        
            alguns serviços aws precisarão tomar ações pelo usuário - IAM Roles - usados pelos serviços - 
                comum ser usado por EC2 (instance Roles), Lambda function role, roles for cloudformation
                
            Area Roles - escolher tipo de entidade - caso de uso - colocar policy - entidades confiaveis - adicionar permissões - criar role
            
        IAM Security Tools 
            credentials report (account level) - usuarios e status de credenciais 
            access advisor (user level) - permissões de serviços dados a usuário e quando foram acessados por ultimo - bom para verificar acessos de forma granular
            
    Boas praticas
        só usar root para setup da conta
        um usuário fisico deve corresponder a um usuario aws
        usar grupos e dar permossões para grupos
        politica de senha forte
        usar e enforçar MFA
        usar access keys para acesso programatico
        fazer auditoria por IAM credentials report e access advisor
        nunca compartilhar access keys e usuários IAM

    etc
        grupos de usuario IAM não podem conter outros grupos de usuario
        statement de policy IAM contem effect, principal, action, resource, dentre outras mas NÃO contem versão
        
EC2

    usuario > billing and cost management > IAM user and role access to billing... > ativar (usuarios IAM tem acesso aos custos)
    free tier - mostra coisas e limites para contas gratuitas. ao passar, é cobrado
    criar budget - alerta de consumo de tiers - manda email
    
    Elastic Compute Cloud - infrastructure as a service
        consiste em alugar vms (EC2), armazenar dados em discos virtuais(EBS), distribuir carga de acesso entre maquinas(ELB), escalar serviços usando grupo autoescalavel (ASG)
        
    Configurações e sizing
        os: Linux, windows, Macos
        cpu, ram, storage(network(EBS, EFS) ou hardware(Ec2 Instance Store))
        placa de rede: velocidade, ip publico
        firewall: grupo de segurança
        bootstrap script: configurações na primeira inicialização - ec2 user data(automatizar tarefas de boot) - updates, instalar software, baixar da internet, etc
        
    Ec2 > instances > launch instances - adiciona nome e tag > imagem base (os)  (AMI) > instance type(potencia da maquina) > key pair (para ssh - pode escolher tipo(rsa, ed25519) e formato(.pem, .ppk))
        > network settings (ip, sec.group com regras, permitir http,https, ssh) > storage(nxsize gbs) - (delete on termination) - advanced details,monte de coisa -> user data (bash p apenas 1st launch)
        > summary (n de instancias) > launch
        
    instancia em execução tem id, ip publico, ip privado(aws), hostname, tipo de instancia, ami, key pair...
    instance state > stop instance - para de cobrar, desliga maquina
    ip publico muda ao reiniciar instancia
    
    Instance Types
        
        propositos - cada proposito tem uma familia de maquinas
        
        m5.2xlarge (m - classe instancia, 5 - geração, 2xlarge - tamanho dentro da classe)        
        
        General Purpose - diversidade, equilibrio
        Compute Optimized - processadores de alta performance - bath, conversão de midia, performance alta, servidor de jogo, machine learning
        Memory Optimized - alto uso de memória ram, DBs em memoria, Cache distribuido, BI, dados grandes não estruturados
        Storage Optmized - Dbs, Cache para bancos em memoria, data warehouse, sistemas de arquivos distribuidos, processameno de transaçoes online com alta frequencia (OLTP)
        HPC Optimized
        Instance Features
        Measuring Instance Performance
        
    Security Groups
    
        controla trafico que entra e sai de instancias ec2 - contem apenas regras allow - regras podem referenciar ip ou grupo de segurança
        firewall de instancias ecs - regulam acesso a porta, intervalo de ip (ipv4 e ipv6) - controlam trafego de entrada e de saída - 0.0.0.0/0 é coringa para "tudo"
        podem ser usados em multiplas instancias, e instancias podem ter multiplos (nxn) - atrelados a combinação região/vpc
        engloba ec2 - se trafego for bloqueado, nunca chega a instancia
        boa pratica um grupo separado para acesso ssh
        se aplicação for inacessivel(timeout) provavelmente é problema de grupo de segurança - se conection refused, security group deixou passar
        
        por padrão todo trafico de entrada é bloqueado e todo trafico de saída é autorizado
        
        referenciar grupo em outro grupo - evitar uso de ips
        portas mais usadas:
            22 - ssh | 21 - ftp | 22 - sftp | 80 - http | 443 - https | 3389 - remote desktop
            
        instancia ec2 > security (ou security groups direto) - inboud rules, outbound rules
        security group tem id, nome, tipo, porta, intervalo de porta, fonte, descrição
        
    SSH
    
        mac e linux e windows 10 - ssh. windows em geral - putty. e instance connect para todos
        configurações rigidas podem dar problemas - tentar ec2 instance connect
        
        arquivo pem/ppk não pode ter espaço no nome - garantir que tem security group q aceita ssh
        
        acesso ssh
        ~> chmod 0400 arquivo_pem_ou_ppk - dar permissão para arquivo chave ser usado se não tiver
        ~> ssh -i arquivo_pem_ou_ppk ec2-user@ip-publico-instancia (ec2-user é padrão de novas instancias ec2)
        
    EC2 Instance Connect
    
        instancia ec2 -> botão "connect" -> ec2 instance connect
        ssh via browser - tem que ter acesso coberto por grupo de segurança - !!! atentar para ipv6
        
        evitar rodar aws configure - nunca entrar chaves IAM em uma instancia EC2 - usar IAM roles - adicionar na instancia
        
    EC2 Instance Purchasing options
    
        on demand - baixa carga, preço previsivel, pago por segundo
        reservado (1 e 3 anos) - cargas longas, conversiveis permitem longas cargas com instancias flexiveis
        spot instances - cargas curtas, baratos, pode perder instancias (menos confiavel)
        host dedicado - reserva um servidor fisico inteiro, controle de uso de instancia
        
        EC2 sob demanda
        
            paga pelo q usa - windows ou linux - cobrado por segundo após o primeiro minuto (outros SO cobram por hora)
            maior custo, mas sem "pagamento de entrada" - sem compromisso de longo termo - recomendado para curto termo e cargas não interrmpidas onde não dá p prever comportamento de aplicação

        EC2 Reserved instances
        
            até 72% de desconto - reserva de atributos especificos como tipo de instancia, região, os
            periodo de reserva entre 1 ano a 3 anos (com descontos maiores no maior periodo)
            pagar em entrada, com entrada ou tudo a vista (com descontos maiores quanto mais antes)
            escopo regional ou zonal - recomendado para aplicações de uso constante, tipo banco de dados
            pode comprar e vender no marketplace proprio
            
            conversivel pode mudar tipo, familia, OS, escopo e tenacidade com desconto menor (até 66%)
            
        EC2 Saving plans
            
            descontos quanto maior termo de uso
            comprometer a certo tipo de uso (10 $ hora por 1 ou 3 anos)
            uso alem é cobrado como sob demanda - travado em familia e região (ex M5 em us-east-1)
            flexivel em tamanho de instancia, OS tenacy
            
        Spot
        
            melhor custo - mas se custo da instancia subir alem do preço maximo q quer pagar, ela é "perdida"
            melhor para trabalhos que são resilientes a falhas como batchs, processamento de imagens, trabalhos distribuidos, com hora flexivel de começo e fim
            não é bom para trabalhos criticos ou bancos de dados
        
        Instancias dedicadas
        
            hardware dedicado - pode dividir hardware com outras instancias na mesma conta - sem controle sob local de isntacia (hardware pode ser movido após stop start)
            
        Reserva de capacity
        
            reserva de instancias sobdemanda em um AZ por uma duração
            sempre terá acesso ao capacity de ec2 quando precisar
            sem comprometimento de tempo (cancela/cria qqr hora) - sem descontos - combinar com instancias reservadas regionais e planos de economia para usar descontos
            cobrança como sob demanda mesmo se não tiver rodando as instancias
            util para trabalho não interrompido de termo curto que precisam ser em um AZ especifico
            
    Spot Instances & Spot Fleet
            
        desconto maior q sob demanda
        definir preço maximo e obter instancias cujo preço é menor que máximo - preço varia sob oferta e capacity - se maior que máximo pode escolher terminar com 2 minutos de graça
        spot block: bloqueia instancia durante intervalo de tempo sem interrupções - pode perder mesmo assim, mas raro
        usado para batchs, analise de dados, e trabalhos resilientes a falhas - não bons para dbs ou serviços críticos
        encerrar instancias - one time | persistent - só pode cancelar requests de instancias nos estados open, active ou disabled - cancelar não termina instancias -
            - primeiro cancelar request de spot depois encerrar instancias spot associadas
            
        spot fleet - conjunto de instancias spot + instancias opcionais sob demanda - spot fleet tenta atingir capacity com limitação de preços
            define possiveis launch pools - tipo de instancia, OS, AZ - pode ter multiplos launch pools - para de iniciar instancias quando atinge capacity ou custo máximo
            
            estrategias para alocar instancias spot
                lowest price - pool com menor preço (otimização de custo, trabalhos curtos)
                diversified - distribuido igualmente por todos os pools (otima disponibilidade, trabalhos longos)
                priceCapacityOptimized - recomendado, pools com maior capacidade e menor preço, nessa ordem (melhor escolha p maioria de cargas)
                
        fleets spot permitem requisitar automaticament instancias spot com menor preço possível
        
        EC2 > spot request > request spot instances
        
    IP publico x IP privado X IP elastico
    
        ipv4 e ipv6 (string longa - menos usado - ioT)
        ip publico pode ser alcançado na internet e é unico - pode ser localizado geograficamente
        ip privado - só identificado em uma rede privada - tem q ser unico na rede privada - conecta na internet usando NAT + proxy
        ip elastico - ao parar e recomeçar uma instancia ec2, o ip publico pode mudar - para não mudar, precisa de um ip elastico - é seu enquanto não apaga
            1 instancia ec2 por vez - 5 por conta - pode usar p mascarar falha, remapeando para outra instancia
            
        Evitar usar ip elastico - refletem escolhas ruins de arquitetura - preferivel ip publico com nome dns registrado
            ou usar load balancer sem ip publico
            
        ip elastico é cobrado mesmo se instancia não estiver em execução
    
    Placement Groups
    
        controlar estrategia de posicionamento (?) de instancias
            cluster - instancias agrupadas em unica AZ em um unico rack em grupo de baixa latencia
            spread - maximo de 7 instancias por grupo por AZ - aplicações criticas - tolerancia a falha
            partição - instancias divididas em partições diferentes em diferentes AZ e racks diferentes - escala centenas de instancias EC2 por grupo (kafka, cassandra, hadoop)
            
        ec2 > network and security > placement groups
            
    Elastic Network Interfaces (ENI)
    
        componente logico na vpc que representa placa de rede
            ipv4 primario e lista de ipv4 secundarios - 1 ip elastico ipv4 por ipv4 privado - 1 ipv4 publico - 1 ou mais grupos de segurança - endereço MAC
            ENI podem ser independentes de instancia ec2 se criadas a parte - podem ser movidas entre instancias - presos a AZ especifico
    
    EC2 Hibernate
    
        Stop - dados no disco (EBS) persistem | terminate - dados que são marcados para destruição são destruidos
        EC2 Hibernate (não a implementação da JPA)
            preserva memoria RAM em arquivo no volume EBS raiz (tem q ter espaço e o volume raiz tem que ser encriptado) - boot é mais rapido
            
        RAM da instancia deve ser menor que 150gb - prazo máximo 60 dias
            
    EC2 Instance Storage
    
        EBS
        
            elastic block store - volume é um drive de rede q pode ser conectado em instancias em tempo de execução
                usa rede -> pode ter latencia | facil de trocar de instancia
            permite que instancias persistam dados mesmo depois de terminadas
            podem ser montados em uma instancia por vez (nivel CCP - nivel arquiteto tem multi attach para alguns EBS) - especifico de um AZ - da p trocar de AZ usando snapshot
                 uma instancia pode ter mais de um
            free tier: 30 gb por mes (SSD ou magnetico) - capacidade provisionada - cobra por capacidade, capacidade pode ser aumentada
            delete on termination - default deleta root ebs e outros não são - configuravel
                p preservar root desativer delete on termination
            
            EC2 > instance > storage
            
            EBS snapshot - backup de EBS - não necessario detachar de instancia, mas recomendado - copia de snapshot é o que pode trancender região e AZ
                podem ser arquivados, sendo mais baratos, mas demora 24 a 72h p restaurar
                tem recycle bin para EBS snapshot, pode ter regras para reter snapshot deletado para recuperar acidentes, retenção pode ser configurada (1 dia a 1 ano)
                recuperação rápida (FSR) - inicialização de snapshot SEM LATENCIA no primeiro uso - custo alto
                
            AMI
                Amazon Machine Image (tipo iso, container docker) - customização de instancia EC2
                boot e config mais rapido pq tudo q precisa (software, configs, etc) já vem pronto
                especifico a região - pode ser copiado p outras
                AMI publico: aws provem. AMI proprio criado e mantido por quem criou, AMI tem market place (vendors podem vender)
                iniciair instancia, customizar - isso cria snapshot EBS - iniciar instancia de outros AMIs - script mesmo formato que EC2 user data
                
            
            EC2 Instance Store
            
                ebs são drives com performance boa boa mas limitada - EC2 instance store é um disco fisico de alta performance - perde dados se instancia para ou é encerrada
                    bom p buffer, cache, conteudo temporario - risco de perda de dados se hardware falhar - backup e replicas responsabilidade do usuario
            
            EBS Volume Types
                gp2/gp3 - ssd de proposito geral - equilibrio entre performance e preço
                    1 gb a 16tb - SO, - dev e testes - gp3 de 3000 IOPS / 125Mb /s e pode subir para 16000 IOPS /1000mb/s - gp2 tem maximo de 3000 IOPS e 5,334  GB mas ligados
                io 1 / io 2 - ssd de alta performance - para trabalhos criticos de alto volume baixa latencia
                    paça 16.000 IOPS - bom para db
                    io1 - 4gb - 16 tb -- max PIOPS 64000 nitro ec2 & 32000 outras instancias - piops pode ser aumentado independente do tamanho do disco
                    io2 - 4gb - 16 tb -- latencia abaxio de milisegundo - max piops 256000 com taxa de iops/gb de 1000/1
                    permite ebs multi-attach
                st1 - HD de custo baixo para uso frequente de alto volume - data warehouse, processamento de logs, big data
                    125gb - 16tb -- hd otimizado para vazão de dados -- 500 mb/s - max IOPS 500
                sc1 - HD de custo baixissimo para acessos menos frequentes
                    125gb - 16tb -- cenarios onde menor custo é importante -- 250 mb/s - max IOPS 250
                    
            EBS multi attach
                attach o mesmo volume ebs para multiplos EC2 no mesmo AZ (io1 e io2 somente)
                cada instancia tem acesso completo de leitura e escrita - maior disponibilidade em aplicações cluster linux (teradata) - aplicações devem lidar com escrita concorrente
                
                até 16 instancias EC2 ao mesmo tempo
                
                tem que usar sistema de arquivos ciente de cluster (não pode ser XFS, EXT4, etc...)
                
            EBS Encryption
                quando encripta EBS: dados em repouso, dados em movimento entre instancia e volume, snapshots e volumes criados do snapshot são encriptados de forma transparente
                    impacto minimo em latencia - chaves KMS (AES-256)
                criar snapshot ebs -> encriptar -> criar volume do snapshot encriptado q vai sair encriptado - anexar volume encriptado na instancia original                
                
        EFS
        
            network file system - pode ser montado em muitos ec2 mesmo em AZ diferentes - encriptação de dados em repouso usando KMS - escala automaticamente, não precisa planejar capacity
            altamente escalavel, disponivel, e caro (3xgp2), pago por uso - usa grupo de segurança para controlar acesso ao EFS, usa protocolo NFSv4.1 - só compativel com AMIs linux
                POSIX fike system - API padrão para arquivos
            web serving, data sharing
            
            EFS scale - 1000s de clientes concorrentes NFS 10gb +/s vazão - pode crescer automaticamente para Pb
            modo de performance - configurado na crianção do EFS
                proposito geral (padrão) - casos de uso sensiveis a latencia (webserver , CMS, etc)
                Max i/o - maior latencia, vazão, altamente paralelo (bigdata, processamento de midias ...)
            modo de vazão
                busting - 1tb a 50mbs + surtos de 100mb/s
                provisioned - configura vazão independente do tamanho do armazenamento - ex 1 gb /s p 1 tb de "disco"
                elastic -  escala automaticamente baseado nas cargas de trabalho - usado para cargas imprevisiveis - até 3gb/s leitura e 1gb/s de escrita
                
            classes de armazenamento
            
                storage tiers - feature de ciclo de vida - move arquivos após N dias - padrão para arquivos de uso frequeente
                    acesso infrequente (EFS-IA) - maior custo para recuperar arquivos e menor para armazenar - habilita EFS-IA com politica de ciclo de vida
                disponibilidade e durabilidade
                    padrão multi-AZ, bom p usar em produção
                    one zone: um AZ, bom p dev, backup habilitado por padrão compativel com IA (EFS one zone-IA)
                90% p mais de economia    
                
            EFS vs EBS
                ebs - 1 instancia - preso a AZ - gp2 aumenta IO se disco aumenta, gp3&io1 pode aumentar IO independentemente - é migrado de AZ via clonar snapshot
                    volumes EBS de instancias podem ser terminados por padrão se instancia EC2 for terminada - desabilitavel
                efs - monta em 100s de instancias de uma vez - apenas posix linux - mais caro - pode usar EFS-IA para tentar minimizar
                

Alta Disponibilidade e Escalabilidade: ELB & ASG

    escalabilidade - aturar maior carga mudando a configuração das aplicações (se adaptando, subindo mais maquina, etc)
    escalabilidades - 
        vertical (hardware - na aws, aumentar "tamanho" da instancia ex t2.micro para t2.large) - rds e elasticache pode ser escalados verticalmente - limite de hardware
        horizontal (elasticidade) - aumento de instancias - sistemas distribuidos - facilitado por aws (EC2, etc)        
    ecalabilidade é diferente, mas ligada a disponibilidade
        disponibilidade na aws consiste em sobreviver a queda de um AZ, tendo aplicações em outros AZ - pode ser passivo (para RDS multi az, por exemplo
            pode ser ativo (para escala horizontal)
    
    menor instancia t2.nano, 0.5gb ram 1 Vcpu, maior instancia - u-12tb1.metal - 12.3TB de ram, 448vCPUS
    scale in (diminuir numero de instancias) out(aumentar) - auto scaling group (pode ser multi AZ), load balancer ( pode ser multi AZ) - sendo multi az aumenta disponibilidade
    
    ELB - Elastic Load Balancing
    
        direciona trafego para multiplos servidores em um sentido (downstream) - usuario -> load balancer -> instancias
        load balancer tem mecanismos de checagem de saude, previne trafego a instancias que falham
        permite expor ponto unico de acesso a aplicação via dns
        alta disponibilidade - provem SSL (https) para sites - enforça sessões com cookies
        separa trafego publico do privado
        
        load balancer gerenciado - aws garante funcionamento, manutenção, upgrade, disponibilidade, e oferece configuração simples
            mais caro que montar load balancer proprio, mas demanda muito mais esforço
        já é integrado com serviços aws como EC2, EC2 auto scaling groups, ECS, AWS certificate manager (ACM), cloud watch, route 53, AWS WAF, AWS global accelerator....etc
        
        Health Checks - porta e rota (/health) se resposta não tiver status 200, instancia é marcada como não ok e não recebe mais trafego
        
        Tipos de Load Balancer
            classic (CLB)- deprecado 2009 - http https tcp ssl - sendo removido
            application (ALB) - v2 - nova geração - 2016 - http https websocket
            network (NLB) - (v2 nova geração) - tcp tls udp 2017
            gateway (GWLB) - camada 3 (rede) - protocolo ip - 2020
        
        recomendado usar novas gerações - mais recursos - alguns load balancers podem ser configurados como ELB internos (privados) ou externos (publicos)
        
        instancias ec2 devem permitir trafego de entrada apenas dos load balancers
        
        ALB (v2)
        
            layer 7 (HTTP) - load balancing para multiplos apps https entre maquinas (target groups) / mesma maquina (containers) 
            suporta http/2 e websocket, redirects (de http para https por exemplo)
            routing para diferentes grupos alvo (baseado em caminho na url, hostname na url, query string e headers)
            bons para microserviços e containers(docker, amazon ECS) - port mapping para redirecionar para porta dinamica em ECS
            precisaria de multiplos CLB por aplicação p fazer o q o ALB faz
            
            Target Groups - ALB pode dar rota para multiplos target groups - health check são feito no nivel do grupo alvo
                instancias EC2 (gerenciadas por Auto Sacling Group) HTTP
                ECS tasks (gerenciado por ECS) HTTP
                funções Lambda (HTTP request é traduzido p json)
                Endereço IPs - tem q ser privados
                
            hostname fixo (ex XXX.region.elb.amazonaws.com)
            servidores de aplicação não vem IP do cliente diretamente - IP real é inserido no header X-Forwarded-For - tb tem X-Forwarded-Port e X-Forwarded-Proto (protocolo)
            
            Listener rules - aplica ações a condições como voltar algo no body da resposta caso a url seja /error
            
        NLB (v2)
        
            Layer 4 - tcp e udp - milhões de request por segundo - latencia baixa (100 ms vs 400ms ALB) - não tem no aws free tier - usa target groups e ip privado
            1 ip estatico por AZ - suporta IP elastico (para whitelist ip especifico?) - em regra acessado por poucos endereços ip            
            é possivel usar un NLB de frente do ALB - ip fixo do NLB e regras do ALB
            health checks por TCP, HTTP e HTTPs
            
        GWLB
            deploy, escala e gerencia fleet de aplicações virtuais terceiras - ex firewall, sistemas de detecção e prevenção, manipulação de payload...
            usuarios --> GWLB ---> target group com aplicações terceiras ---> GWLB ----> aplicação destino
            Layer 3 (Network) - pacotes IP - combina transparent network gateway (ponto de entrada/saida unico para todo trafego) com load balancer (distribui trafego para app virtuais)
            protocolo GENEVE porta 6081
            
        Elastic Load Balancer - Sticky Sessions (Session Afinity)
        
            mesmo usuário é redirecionado pelo load balancer para mesma maquina
            funciona no CLB, ALB e NLB - cookie com data de expiração - manter sessão, mas pode causar desequilibrio de carga nas instancias de backend EC2
            cookies podem ser 
                app based - custom cookie - gerado por alvo, pode incluir atributos personalizados q app precisa - nome precisa ser especificado para cada target group - 
                    não usar nomes reservados como AWSALB, AWSALBAPP, AWSALBTG
                app based - application cookie
                    gerado por load balancer - nome AWSALBAPP
                duration based - gerados por load balancer, nome AWSALB para ALB ou AWSELB para CLB
                
            target group > edit attributes > stickness
            
        Elastic Load Balancer - Cross Zone
        
            com cross zone, carga é distribuida de forma igual entre todas as instancias em todas as AZ, causando com que AZs recebam trafego desigual para que instancias tenham trafego igual
            sem cross zone, AZs recebem trafego igual, e instancias recebem trafego divido de sua AZ
            no ALB, habilitado por padrão, pode ser desabilitado no target group - sem cobrança em dados inter AZ
            no CLB, desabilitado por padrão, pode ser habilitado no target group - sem cobrança em dados inter AZ
            no NLB e GWLB desabilitado por padrão, dados entre AZs são cobrados
            
        Elastic Load Balancer - SSL Certificates
        
            certificado SSL permite trafego entre clients e load balancer ser encriptado em transito (in-flight)
            SSL - secure sockets layer, versão mais nova é TLS que é mais usada, mas é referida como SSL mesmo assim
            emitido por autoridades de certificado (CA) - comodo, symantec, GoDaddy... - expiram e precisam ser renovados - data escolhida pelo usuario?
            
            usuario <---https encriptado por www---> load balancer <----- http por vpc ----> instancia EC2
            Load balancer usa X.509 certificate (SSL/TLS) - gerenciados por AWS Ceriticate Manager (ACM) - pode criar os seus e fazer upload
            Https listener - especificar certificado padrão, lista opcional de certificiados para multiplos dominios , SNI para especificar hostname que alcançam
                pode especificar politica de segurança para suportar versões mais velhas de SSL/TLS (legado)
                
            SNI - Server Name Indication
                resolva problema de carregar multiplos SSL cert. em um site - protocolo mais novo q exige q cliente indique o hostname do servidor alvo para handshake inicial do SSL
                    servidor acha certificado correto ou retorna o certificado padrão (cliente -->ALB (certificados, escolhe usando SNI) ---> target group )
                só funciona com ALB e NLB nova geração e CloudFront - não funciona para CLB
            
            certificados são habilitados dentro de listeners em EC2 > Load Balancers > nome_load_balancer > add Listener >
            
        Elastic Load Balancer - Connection Draining
            
            Connection draining para CLB e Deregistration Delay para ALB e NLB - tempo para completar requests in flight enquanto instancia está desligando ou nao saudavel
            parametrizavel
            instancia ec2 para de receber rquests quando vai desligar - valor zero desabilita
    
    ASG - Auto Scaling Groups
    
        auto escalar instancias ec2 para lidar com variação de carga - parametrizar min e max de instancias
        automaticamente registra novas instancias para um load balancer - recria instancia EC2 se instancia não estiver sadia - 
        ASG é gratuito, paga pelas instancias ec2 apenas
        
        launch configurations é deprecado - agora é launch template
        contem atributos como AMI + instance type, EC2 user data, EBS volume, security groups, SSH key pair, IAM roles para instancias, info de rede e subrede, info de load balancer
            parecido com ec2
        min, max, scaling policies
        possivel de escalar baseado em alarmes do cloudwatch - metricas como cpu medio, ou personalizada
        
        ASG Scaling Policies
        
            dynamic - 
                target tracking scaling (simples) - ex average CPU manter em 40%
                simple / step scaling - quando alarme do cloud watch é disparado (ex cpu > 70% subir mais duas maquinas)
                scheduled - ex aumentar capacidade minima sexta das 10 am as 5 pm
                preditiva - preve a partir de dados historicos e adianta escala
                
            metricas boas para escalar - average CPU nas instancias, RequestCountPerTarget, average network in/out, personalizado
            scaling cooldown - padrão 300s - ASG não muda numero de instancia nesse tempo, esperar metricas estabilizarem
                usar AMI ready to use para reduzir tempo de configuração para atender request mais rapido e diminuir periodo de cooldown
            
            
AWS Fundamentals: RDS + Aurora + ElastiCache

    RDS
        Relational Database Service - SGBD usando SQL - na nuvem gerenciados por AWS
        Postgres, Mysql, MariaDb, Oracle, Sql Server, DB2, Aurora (da AWS)
        é melhor usar RDS q subir SGBD na EC2 - backups, patches de OS, provisionamento automatico, dashboards, replicas de leitura, config multi AZ, janelas de manutenção, escalabilidade
            horizontal e vertical, armazenamento usando EBS (gp2 ou io1)
                porem NÃO dá para entrar por SSH nas instancias EC2 do Rds
        RDS Storage auto scaling - aumenta espaço dinamicamente e automaticamente - configurar Maximum Storage Threshold
            automaticamente aumenta espaço se espaço livre é menos de 10% do total alocado, pouco espaço dura pelo menos 5 minutos, e 6 horas passaram da ultima modificação
                util para aplicações com carga imprevisivel - suporta todos Dbs do RDS
    
    RDS read replicas vs Multi AZ
        read replicas - até 15, dentro de AZ ou cross AZ ou cross Region, replica é Async - eventualmente consistente - replicas podem ser promovidas para proprio DB
            aplicações tem que atualizar string de conexão para usar das replicas de leitura
        caso de uso - aplicação de relatorio
        NÃO tem custo quando dados mudam de AZ para replicas. TEM custo quando muda de região
        
        multi AZ - uso para recuperação de desastres - replica sincrona do mestre para standby - um nome dns que muda para standby em desastre (mais disponibilidade)
        apps não precisam de intervenção manual - não usado para escalabilidade
        !!! replicas de leitura podem ser configuradas como multi AZ !!! -> sem tempo de queda - clicar modify no banco de dados e habilitar multi AZ
            snapshot é tirado -> novo DB é restaurado de snapshot em novo AZ -> sincronização é estabelecida entre os dois bancos de dados

        AMAZON RDS > databases > create database
            usar io1 para produção
            standard creation dá mais opções que easy
            availability dá p colocar multi az para confiabilidade e disponibilidades
            conectivity - facilita conexão com maquina ec2
            acesso publico permite acesso ao db de computador externo
        
    RDS custom
        para SQL server e Oracle - acesso ao OS e ao DB por trás do serviço e instancia EC2 usando SSH ou SSM (session manager) - 
            mantem todas automações do RDS
            desativarmodo automação e tirar snapshot do banco são recomendados antes de usar custom
            
    Aurora
        não open source - compativel com postgres e mysql - otimizado para nuvem (5x performance do mysql rds, 3x performance do postgres rds)
        espaço cresce automaticamente em incrementos de 10 gb até 128 tb
        até 15 replicas, mais rapido q mysql (sub 10ms) - failover é instantaneo (menos de 30s) - alta disponibilidade
        20% mais caro que RDS
        guarda 6 copias atravez de 3 AZ - 4 copias para escrita, 3 copias para leitura (de 6) - auto cura com replica p2p
        espaço é dividido em centenas de volumes - 1 mestre cuida de escrita - mestre e até 16 replicas cuidam de leitura - auto scaling
        Cluster - tem um ponteiro chamado writer endpoint - reader endpoint (faz load balance e conecta a replica de leituras)
        
        todas vantagens do rds, mais backtrack (ponto de restauração que não precisa de backup)
        aurora cluster não pode ter região em particular pq é global
        
        Replica auto scaling - extende reader endpoint p cobrir novas replicas
        custom endpoints - subconfjunto de instancias (por exemplo, tirar relatórios ou analytics - reader endpoint não costuma ser usado em conjunto
        serverless - auto scaling e auto instancing - bom para cargas de trabalho imprevisiveis, não precisa de planning de capacity - paga por segundo, pode ser mais custo eficiente
        global aurora database - tem região primaria e até 5 regiões somente leitura com até 16 replicas de leitura cada - promover outra região tem tempo menor que um minuto em caso de desastre
            replica cross região leva menos de 1 segundo
        machine learning - adicionar previsões para aplicações via SQL - simples, otimizado, integrado e seguro se integrado com serviços machine learning da AWS
            suporta sage maker (qqr modelo de ML) e Comprehend(sentimental analysis)
            diz q não precisa de experiencia com ML - usa com fraud detection, ads, recomendações
            
    RDS & Aurora - Backup e monitoria
        RDS
            diário (durante janela de backup) - logs de transação são backupeados a cada 5 minutos - permite ponto de restauração - 1 a 35 dias de retenção, 0 desabilita backups automaticos
            Snapshot manuais - retenção por tempo indeterminado - em banco RDS parado é cobrado armazenamento. se parar muito tempo compensa tirar snapshot e restaurar depois
        Aurora
            1 a 35 dias não desligavel - ponto de restauração
            Snapshot manuais - retenção por tempo indeterminado
        Restaurar
            restauração cria novo banco de dados
            é possível restaurar MySQL de S3
            para restaurar aurora mysql usa Percona Xtrabackup - manda p s3 - restaurar p aurora cluster com mysql
        Aurora DB Cloning - cria DB de um existente - bom p gerar bancos de teste por exemplo - mto rapido - copy on write protocol (usa mesmo volume de dados)
        
    RDS & Aurora Security
        at rest encryption: AWS KMS - definido na criação - se mestre não encriptado, replicas também não - para encriptar banco encriptado, fazer snapshot e restaurar encriptado
        in flight encrypt. : TLS ready por padrão, usa AWS TLS root certificates na criação
        IAM authentication: roles IAM para conectar no banco ao invés de user/password
        Security Groups: controle acesso de rede ao RDS/Aurora - sem ssh com exceção de RDS custom - logs podem ser habilitados e enviados ao cloudwatch para maior retenção
        
    RDS Proxy
        proxy gerenciado para RDS - agrupar e compartihar conexão de DB com banco - aumenta eficiencia minizando conexões, timeouts e uso de recursos
        serverless autoescalavel multi AZ - tempo de failover reduzido até 66% - suporta RDS e aurora - sem necessidade de mudar apps - enforça autenticação IAM e AWS secrets manager
                                                                                    (MYSQL, postgres, mariaDB, Sql Server)
        proxy nunca é acessivel publicamente, precisa ser acessado por VPC - muito usado com lambda

    ElastiCache
        redis ou memcached gerenciados por AWS (cache, banco em memoria rapido para dados que mudam pouco etc) - requer mudança de codigo p usar
        guarda sessão para app ficar stateless
        
        redis - multi AZ com auto failover, replicas de leitura, durabilidade de dados, suporta sets e sets ordenados
        memcached - multinode partição de dados (sharding) - sem replica, sem persistencia, sem backup, multithreaded - (cache puro perdivel)
        
    ElastiCache - Cache Security
        IAM authentication for roles - só usado para nivel AWS API
        redis auth - password/token quando cria cluster, nivel extra de segurança, suporta SSL in flight encript.
        memcached - autenticação SASL (avançado)
        
        patterns
            lazy loading - todo dado de leitura é cacheado, pode ficar defasado
            write through - atualiza dados quando banco sofre escrita - sem defasagem
            session store - guarda dados temporarios de sessão em cache
        
        
Route 53

    DNS - converte nome legivel para ip - espinha dorsal da internet - estrutura hierarquica
        domain registrar: amazon route 53, goDaddy...
        dns records: A, AAAA, CNAME, NS...
        Zone file: contem registros dns
        name server: resolve consultas dns (autoritativa ou não autoritativa)
        top level domain: com, us, in, gov, org
        second level domain: amazon.com, google.com
        sub level domain: www.google.com
        Full qualified domain name: tudo depois do protocolo
        URL: protocolo + nome qualificado
        
        web browser ---nome site---> local dns --nome site-----> serviodres dns
                <----ip-------------            <-----ip---------
                
    altamente escalavel, disponivel, gerenciado e autoritativo ( usuario do route 53 pode atualizar registros dns)
    também é domain registrar - habilidade de ver saude de recursos - unico recurso que dá 100% de disponibilidade
    53 também é a porta padrão do dns
    
    Registros
    
        como rotear trafico para dominio
        dominio/subdominio, tipo(A, AAAA, CNAME, NS...), valor, routing policy, TTL
        
        Tipos:
            A - mapeia hostname para ipv4
            AAAA - mapeia hostname para ipv6
            CNAME - mapeia hostname em outro hostname (alvo pode ser A ou AAAA) - não pode criar CNAME para nó no "topo" de um namespace DNS (Zone Apex)
                ex: não pode criar CNAME para example.com, mas pode para www.example.com
            NS - name servers de hosted zone - controla como trafico e roteado para um dominio
        
        Hosted Zones - container para registros que definem como rotear trafego para dominio e seus subdominios - 50 centavos de dolar por mês
            public - registros para rotear trafego na internet (nome de dominios publicos)
            private - registros para rotear trafego dentro de VPC (intranets)
    
    Route 53 > Registered Domains > Register Domain > procura dominio e preço > checkout (duração e auto renew)
    
    comando no cloud shell > nslookup url, dig url
    
    TTL
        não muda tanto - se TTL for alto, tipo 24h, tem menos trafego mas pode ter dados defasados. se baixo, tipo 60s, mais trafego (maior custo), menos defasagem
        pode ser mudado para se adequar a cenário, estratégia, etc
        TTL é obrigatorio para todos os registros DNS com exceção de alias
    
    CNAME vs Alias
        CNAME - aponta hostname para outro hostname - APENAS para dominio não raiz
        alias - aponta hostname para recurso AWS (só AWS) - dominio raiz e não raiz
            reconhece automaticamente mudanças de IP do recurso - pode ser usado por top node de namespace DNS (Zone Apex) - sempre do tipo A ou AAAA a depender da versão do IP - TTL automatico apenas
            pode ser load balancer, cloudfront, gateway, beanstalk, s3 websites, vpc interface endpoints, global accelerator accelerator, route 53 record na mesma hosted zone
            Não dá p ter Alias para DNS de EC2
    
    Routing Policy - Simple
        routing em dns não é como load balancer que distribui request, mas sim como responde a queries de dns
        rota trafego para unico recurso - se multiplos valores retornados por dns, um aleatorio é escolhido pelo client.
        quando alias habilitado, especifica apenas um recurso aws - simples, logo não pode ser associado a health check
        
    Routing Policy - Weighted
        porcentagem de requests para recurso especifico baseado em "peso" - cada registro tem um peso configurado relativo - registros dns precisam ter mesmo nome e tipo
        pode ser associado com health check - usado para testar novas versões de aplicações, load balancing entre regiões - peso zero causa parada de transferencia para registros
            se todos os pesos forem zero, distribuição igual para registros
            
    Routing Policy - Latency
        redireciona para recurso com menos latencia mais perto (nessa ordem) - baseado em trafego entre usuarios e regiões AWS - pode ter health check
            usuario da alemanha pode cair nos estados unidos se latencia lá for menor
            
    Health Checks
        http, apenas para recursos publicos - se falha, failover de dns automatico (pode ser monitoria de endpoint, recurso aws, outros health checks(calculated health checks), alarmes cloudwatch
        para endpoint, metrica propria integrada com cloudwatch - 15 health checker globais vão checar saude dele.
            threshold: 3 (padrão) - intervalo 30 segundos (pdoe ser até 10s, mas é mais caro) - http, https, tcp - se mais q 18% dos HC considerar endpoint saudavel, route 53 considera saudavel
            pode escolher qual localização de health check o route 53 usa - aprovação é só para respostas nas familias de status 2xx e 3xx.
            pode ser configurado para passar / falhar baseado no texto nos primeiros 5120 bytes da resposta
            possivel configurar router/firewall para permitir requests dos health checks do route 53
            
        calculated health checks - combina vários health check em um unico - usando or, and e not - até 256 health checks filhos em 1 - especificar quantos precisam passar p pai passar
            uso: fazer health check de um site sem cair todos os health checks e gerar falso positivo/bagunçar metrica
        Health check para Private Hosted Zones - HC publicos de route 53 são todos fora de vpc e não conseguem acessar endpoint privado
            criar metrica de cloud watch, associar alarme de cloud waatch e fazer health check q verifica o alarme
            
    Routing Policy - Failover
        ativo-passivo: se registro primario falha, muda para secundario
        
    Routing Policy - Geolocation
        baseado no local do usuario - pode ter health check, cria registro padrão se não tiver match com localização, precisão de localização em continente > pais > estado US
            se tiver local que cai em 2 locais, precisa especificar qual local vai usar - usado com local de site, restrição de conteudo, load balancing
            
    Routing Policy - Geoproximity
        baseado na localização de usuarios E recursos - usa configuração "bias" para mudar trefego a recursos
            aumenta bias -> mais trafego, diminui -> menos
        recursos podem ser AWS(especificar região AWS) e não AWS(especificar latitude e longitude) - depende do recurso traffic flow do route 53 (bem avançado)
    
    Routing Policy - Ip based
        baseado no ip do cliente -> provem lista de intervalo de ips e endpoint/localizações correspondentes
        otimiza performance, reduz custo de redes - ex rotear usuarios de um provedor de internet para um endpoint especifico
    
    Routing Policy - Multi Value
        usado para rotear trafego para multiplos recursos - rentorna multiplos valores/recursos - tem healthcheck (só retorna saudaveis) - até 8 registros saudaveis são retornados por query multivalor
        Não é substituto de ELB
    
    3rd Party Domains - Domain Registrar x DNS Service
        dominios são pagos por ano - domain registrar geralmente dá um serviço dns para gerenciar registros dns
        pode usar outro serviço de dns para gerenciar recursos (ex usar route 53 com dns e godaddy com dominio ou usar dns externo e dominio do route 53)
            feito usando nameservers customizados q foram criados no route 53
    

Problemas Classicos de Arquitetura de Soluções
    
    whatIsTheTime.com - pessoas podem ver que horas são - stateless
        não precisa de DB, pode ficar fora, mas precisaria de escalaar vertical e horizontal e depois tirar downtime
        
        solução mais simples: usuario ----request-----> EC2 publico t2.micro com ip elastico responde -----> usuario
        
        escala vertical: usuario ----request-----> EC2 publico m5.2xlarge com ip elastico responde -----> usuario
        
        escala horizontal: usuario ----request----> route 53 (TTL 1h, registro tipo A)---> EC2 publico m5.2xlarge x3 responde -----> usuario
        
        horizontal com load balancer
            usuario ----request----> route 53 (TTL 1h, alias)---> ELB (publico) +  health checks ----->security groups----> EC2 privado m5.2xlarge x3 responde -----> usuario

        horizontal com load balancer e auto scaling
            usuario ----request----> route 53 (TTL 1h, alias)---> ELB (publico) +  health checks ----->security groups----> ASG(EC2 privado m5.2xlarge)  responde -----> usuario
            
        horizontal com load balancer e auto scaling e multi AZ
            usuario ----request----> route 53 (TTL 1h, alias)---> ELB (publico) + HC + MultiAZ ----->security groups----> ASG(multi-AZ(EC2 privado m5.2xlarge))  responde -----> usuario
            
    myClothes.com - app web stateful - ecommerce de roupas - carrinho - centenas de usuarios - tem q ser escalavel horizontal e o mais stateless possivel - tem DB
        inicio: user -->route53-->ELB multiAZ-->ASG(m5.2xlarge) em 3 AZs mas usuário aleatóriamente perde carrinho de compras
        
        cookie: user + cookie com carrinho-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs porem carrinhos ficando epsados e cookies podem ser alterados por ofensores
        
        cookie 2: user + cookie com carrinho-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs com cookies pequenos(4kb) e validados por cada instancia
        
        cookie 3: user + cookie com sessionId-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs --> Elasticache (session data) ou DynamoDb
        
        cookie+Db: user + cookie com sessionId-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs --> Elasticache (session data) ou DynamoDb
                                                                                                                    --> Amazon RDS (dados de cliente)
                                                                                                                    
        cookie+Db: user + cookie com sessionId-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs --> Elasticache (session data) ou DynamoDb
                                                                                                                    --> Amazon RDS (dados de cliente) - escalar leituras com replicas
                                                                                                                    
        DR: user + cookie com sessionId-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs --> Elasticache (session data) ou DynamoDb multi AZ
                                                                                                             --> Amazon RDS (dados de cliente) - escalar leituras com replicas multi AZ
            restringir trafego externo ao LB, trafego p EC2 apenas do LoadBalancer e RDS apenas recebe de EC2
            
    myWordPress.com - blog escalavel - exibir imagens de forma correta - armazenar conteudo via mysql
    
        arquitetura: user + cookie com sessionId-->route53-->ELB multiAZ + stickness + HC -->ASG(m5.2xlarge) em 3 AZs --> RDS MultiAZ com replicas de leitura
                                                                                                    |--ENIs--->EFS (permite escalar pois é compartilhado por EC2s)
                                                                                                    
    Instanciando aplicações rapidamente
        começar stack completa do zero (EBS,EC2,RDS) pode demorar (instalar apps, dados iniciais ou de recuperação, configurações, iniciar app)
        Ec2 - golden AMI - AMI tem tudo e é só rodar AMI
            bootstraping user data: configurações dinamicas
            hibrido - tem combinação dos dois (Elastic Bean Stalk)
        RDS - restaura de snapshot q vem com schemas e dados
        EBS - restaurar do snapshot
        
    Beanstalk
        origina de problemas de desenvolvedor na aws - gerenciar infra, deploy de codigo, configuração de load balancers,dbs, escalabilidade
            muitas aplicações web tem arquitetura parecida (ALB + ASG) - devs querem só testar codigo
        visão de desenvolvedor - de uma interface, deploy de tudo, ASG, ELB, RDS, EC2, etc... dev só mexe com codigo
        total controle de configurações - serviço beanstalk é gratis, o q é cobrado são as coisas q ele usa
        
        Componentes
            Aplicação: coleção de componentes de beanstalk (envs, versões, configs)
            Ap. version: iteração do código
            Environment: coleção de recursos AWS rodando UMA versão da aplicação por vez - Tiers (web ou worker) - pode ter mulitplos (dev, test,prod...)
            criar app (1) --> upload de versão (2) --> executar ambiente(3) --> gerenciar ambiente (4) ---- iterações repetem do 2 ao 4
            suporta Go, java, java tomcat, .net core linux, .net widows, node.js, php, python, ruby, packer builder, docker de container unico/multi/preconfigurado
            tier web escala por requisição no load balancer, tier worker escala por mensagem no sqs?
            deployment modes
                single instance - bom p dev
                high availability - bom p prod
        
        Boa pratica usar um IAM role para usar no beanstalk

        
S3

    um dos principais componentes - armazenamento de escala infinita - usado por muitos sites e serviços aws p integração
    backup e armazenamento - disaster recovery - arquivamento - armazenamento hibrido na nuvem - host de app e media - datalake e bigdata - sites static - delivery de software
    
    Buckets
    
        diretorios(buckets) que contem arquivos (objetos) - nomes tem que ser unico globalmente (em todas as regiões e todas as contas)
        buckets são regionais e não globais - convensão de nome não pode ser captalizado, nem ter '_', entre 3 e 63 de tamanho, não começar com xn-- nem terminar com -s3alias,
            não pode ter nome como ip, e tem q começar com numero ou letra minuscula
            
        objetos (arquivos) tem chave (path completo - ex s3://my-bucket/file.txt) - prefixo + nome de objeto
        não tem pasta dentro dos buckets, por mais q pareça na UI - tudo é chave com nomes longos
        valores são conteudo do body - até 5 TB, se mais q 5GB tem q usar upload multipart
        metadados são lista de pares chave/valor, tags, version Id
        
        url pode ser publica (vista por quem deve ver) ou ser pre-assinada (vista pelo dono)
        
    Security: Bucket Policy
        user based - IAM policies - quais chamadas de api podem ser permitidas para usuarios especificos de IAM
        resource based
            bucket policies - regras q atingem bucket do console s3 - pode ser cross account
            object access control list - mais granular (pode ser desligado)
            bucket access control list - raro, pode ser desabilitado
            
        usuario IAM principal pode acessar objeto S3 se:  (permissões de usuario permitem OU politica de recuso permite) E não tem negativa explicita
        
        baseado em Json - podem permitir ou negar buckets e/ou objetos
            contem principal(contas), efeito (permitir, negar), recursos afetados, ações(conjunto de ações de API como s3:GetObject)
        
        pode ser usado para dar acesso publico ao bucket, forçar encriptação de objetos ao upload, dar acesso a outra conta
        ex: permitir acesso de ec2 ao bucket - atribuir role para instancia com permissão IAM
        
    S3 Website - sites estaticos acessiveis pela internet - url depende da região - precisa de permissão de leitura publica - tem q ter index.html
    
    S3 Versioning
        habilitado em nivel de bucket - escrita de mesma chave muda versão - boa pratica versionar, pois protege de deletes acidentais e é facil fazer rollback
        arquivos não versionados tem versão nula antes de começar a salvar novas versões com versionamento ligado
        desligar versionamento NÃO apaga versões anteriores -> adiciona delete marker, age como apagado mas se marker for apagado, original volta
        
    S3 Replication
        Cross Region (CRR) - compliance, latencia menor, replica entre contas 
        Same Region (SRR) - agregado de logs, replicação entre prod e homologação
        precisa habilitar versionamento nos buckets origem e destino - buckets podem ser de contas diferentes - assincrono - precisa de permissões IAM adequadas para S3
        
        só novos objetos são replicados após habilitar -> para replicar "velhos", usar s3 batch replication (existentes e que falharam)
            para operações de delete pode replicar delete markers (opcional) -> deleções com version ID não replicados (evitar delete malicioso)
        não dá p encadear replicação -> se objetos são replicados de bucket1 p bucket2 q replica p bucket3, objetos criados em bucket1 não vão automaticamente para bucket3
        
    S3 Storage Classes
        é possivel mudar de classe manualmente ou usando config de ciclo de vida do s3
        durabilidade - 99,99999999999% de objetos através de multiplos AZ - se guardar 10 mi objetos é esperado que perca 1 a cada 10 mil anos - vale para todas as classes
        disponibilidade - depende da classe (ex s3 standard fica fora 53 minutos por ano)
        
        s3 standard - geral - 99.99% disponivel - dados acessados frequentemente - baixa latencia, alto volume - suporta duas falhas concorrentes de "facility" - big data, apps, content...
        s3 IA (infrequent access) - 
            dados pouco acessados mas q precisam de acesso rapido - mais barato q standard - subtipos standard IA(99.99 disp, disaster recover) e one zone IA (99.9999999% dur. 1 AZ)
        s3 glacier - baixo custo - arquivamento e backup - cobrado espaço e taxa de retirada
            instant retrieval - acesso em ms, tempo minimo 90 dias
            flexible retrieval - acesso em categorias: expedited (1 a 5 min), standard (3 a 5h), bulk (5 a 12h - gratis) - minimo 90 dias
            deep archive - standard (12h), bulk (48h) - minimo 180 dias
        s3 intelling-tiering
            taxa baixa mensal de monitoria e auto-tier - move automaticamente objetos entre tiers baseado em uso - não tem taxa de retirada
            frequent access - default - auto
            infrequent access - auto - objetos sem acesso por 30 dias
            archive instant access - auto - objetos sem acesso 90 dias
            archive access - opcional - configuravel entre 90 a 700+ dias
            deep archive access - opcional - config. entre 180 a 700+ dias
            
    S3 Lifecycle Rules & Analytics
        move automaticamente objetos entre classes
            ações de transição - config para transicionar p outra classe (objetos para std IA depois de 60 dias e glacier depois de 6 meses)
            ações de expiração - expira objetos depois de periodo - apagar logs, versões antigas, multiparts incompletos
        regras podem ter prefixo (ex s3://mybucket/mp3/*) e tags (ex department:finance)
        
    S3 Requester Pays
        no geral, donos do bucket pagam todo armazenamento e transferencias de bucket - buckets requester pays o pedinte paga download
        util p dividir datasets enormes com outras contas - requester precisa estar autenticado na aws - não pdoe ser anonimo
        
    S3 Event Notifications
        S3:ObjectCreated, S3:Replication ... - possivel filtrar por nome de objeto - evento pode ir p lambda, sqs, sns - quantos quiser - entregues em segundos mas pode demorar minutos
        precisa de permissões IAM para invocar recursos - resource access policy do serviço também é necessario
        todos eventos vão parar em event bridge - eventos ---> bucket s3 -> event bridge --regras--> mais de 18 serviços AWS
            filtro avançado com regras JSON (metadados, tamanho, nome...) - multiplos destinos - capacidades de event bridge (arquivar, replay, entrega confiavel)
            
    S3 Performance
        s3 escala automaticamente para taxas altas de requests, mantendo laencia entre 100 e 200 ms - app pode chegar até a 3500 put/copy/post/delete ou 5500 get/head requests p seg por prefixo p bucket
        não há limite de prefixo por bucket - se 4 prefixos , pode chegar a 22000 get/head por segundo
        
        multi part upload pode aumentar performance paralelizando upload das partes
        s3 transfer acceleration - aumenta velocidade transferindo arquivo para outra localidade aws mais perto primeiro e depois transferindo p bucket na região destino
            compativel com multipart
            arquivo usa ---rede publico--->local edge(mais perto) usa ---rede privada aws----> bucket australia

        s3 byte range fetches - paraleliza get pedindo faixas especificas de bytes - mais resiliente em falhas - aumenta velocidade de downloads paralelizando bytes fetches
        
    S3 Select & Glacier Select
        recupera menos dados usando sql para filtrar em nivel servidor - filtra linhas e colunas com sql simples, mais custo efetivo
        
    S3 Batch Operations
        operações em lote usando um unico requests - mudar metadados de muitos objetos ao mesmo tempo, copiar objetos entre buckets, encriptar objetos não encriptados, restaurar objetos da glacier
        ação de lambda para cada objeto
        job é lista de objetos e parametros opcionais - melhor q codigo proprio pq tem rastreio de progresso, retentativa, relatorio, notificação, etc
        usar s3 inventory para gerar lista e usar s3 select para filtrar
        s3 inventory -lista objetos-> s3 select ->lista filtrada -> s3 batch (operações + parametros de usuario) -> resultado
        
    S3 Storage Lens
        analise e otmização de armazenamento por toda organização na aws - agrega dados por região, buckets, prefixosz, contas - dashboard padrão e customizavel - exportar metricas diariamente p bucket
            csv, parquet
            dashboards podem ser multi conta e multi região - pode ser desabilitado não deletado
        metricas de resumo (gerais como bytes, num de objetos) - identificar uso de buckets
        metricas de custo (nomcurrentversion, incompletemultipart, etc) - ver q objetos podem ir p classes mais baratas
        metricas de protecao de dados(corssRegionReplicationRuleCount,) identificar dados não sseguros e replicados
        metricas de acesso (objectOwnershipBucketOwnerEnforcedBucketCount) - quais configurações buckets usam
        metricas de evento
        metricas de performance - identificam qual bucket tem aceleração ativa
        metricas de atividade - storage requests
        metricas de status - codigos http - contagens
        
        metricas gratis - automaticamente disponivel p tdos - 28 metricas de uso - 14 dias disp. p queries
        metricas avançadas - pagas
            atividade, custo, proteção, status, cloudwatch vem de brinde, agregação de prefixo, 15 meses disp. queries


S3 Security

    S3 Encryption
        4 metodos:
            server-side(SSE):
                with amazon s3-managed-keys (SSE-S3)- padrão habilitado - encripta objetos usando chaves manuseadas gerenciadas e de posse da aws
                    AES-256 - precisa de header x-amz-server-side-encryption:AES256 - objeto é combinado com chave para encriptar
                wuth kms keys stored in aws kms (SSE-KMS) - serviço de gerenciamento da aws (key management service) - usuario gerencia usando serviço
                    permite maior controle usuario - auditoria de chave com cloudTrail - header x-amz-server-side-encryption:aws:kms
                    kms tem limites - usa apis do kms q contam nas cotas de kms calls per second - pode aumentar cota no console
                with customer provided keys (SSE-C) - usuario gerencia chaves
                    aws não guarda chave de encriptação, discarta depois do uso - precisa de https, como header de todas as chamadas feitas
            client side encryption
                usa bibliotecas da aws via client side - usuario que encripta dados e decripta - tudo responsabilidade do usuário
                
        encryption in transit/flight (SSL\TLS) - S3 expõe 2 endpoints - http não encriptado e https com encriptação em transito/voo
        recomendado usar https sempre mesmo sem ser SSE-C
        forçar encriptação em transito pode ser feito usando bucket policiy - negar quando flag aws:secureTransport: false
        
        tem um uqinto metodo, double encription based on kms (DDSE-KMS)
        
    Default Encryption
        
        sse-s3 é padrão para todos objoetos novos no bucket - politicas de bucket são avaliadas antes da encriptação padrão
        
    S3 CORS
    
        Cross-Origin Resource Sharing - origem é schema (protocolo) + host (dominio) + port
            permite outras origens enquanto visitam origem principal - se browser tá em um site e faz request p outro, só funciona se outro site permite o request usando header CORS
                (ex header CORS: Access-Control-Allow-Origin) - pode ter metodos permitidos ou negados (GET, PUT, etc) - site "outra origem" pode dizer de que sites aceita request CORS
            é possivel habilitar algumas origens ou * (todas)
    
    MFA Delete
        força usuarios a gerar codigo no aparelho antes de fazer operações importantes
            exigido para deleção permanente - suspender versionamento no bucket - só dono bucket / conta root pode habilitar MFA delete
                versionamento precisa estar habilitado no bucket para usar MFA delete

    Access Logs
        auditoria - logar todos acessoss a s3 de todas as contas todos status em arquivo em outro bucket q pode ser usado com analytics -> bucket alvo tem q ser da mesma região
            formato especifico - NUNCA USAR MESMO BUCKET p log q bucket q quer logar - vira loop infinito e cresce exponencialmente
            
    Pre-signed Url
        gerar url pre assinadas com console, aws cli or sdk
        expiração - console: 1minuto a 720 minutos (12h) - aws cli - padrão 3600 segs, config. até 168h - usuarios da url herdam permissões do usuario q gerou url p GET/PUT
            permitir apenas usuarios logados de baixar video do s3, permitir uma lista altamemente mutavel de baixar arquivos gerando urls dinamicamente
            
    S3 Glacier Vault Lock & S3 Object Lock
        worm - write once read many
        para isso precisa de vault lock policy e depois trancar para edicções - bom p compliance e retenção de dados - nem admin consegue apagar
        para bucket , object lock - precisa de versionamento - bloqueia deleção de versão de objeto por tempo
            retenções - compliance - igual glacier e governance - maioria dos usuarios não consegue apagar ou editar (dados por IAM)
                precisa de periodo de retenção - pode ser extendido - legal hold protege objeto pra sempre - alguem pode configurar isso (precisa de permissão IAM)

    S3 Access Points
        Access point policy (parecido com bucket) - permite acesso a prefixo especifico (ex: permitir acesso de usuarios a certos "dominios" de bucket via prefixo)
        simplifica segurança para buckets - cada um tem proprio dns (internet ou vpc)
        
        vpc origin - pode ser privado - tem q ter acesso endpoint da vpc q tem propria policy e tem q permitir acesso para bucket e access point p usar o access point
        
    S3 Object Lambda
        usa lambda para modificar objeto antes de enviar para pedinte - precisa de bucket, access point e s3 lambda access point
            util p converter dados (JSON, XML) ou por marca dagua e redimensionar imagens
            
            app --------objeto original ------ s3 ---- s3 access point --- lambda ----- lambda s3 access point ---- usuario
            

CloudFront & Aws Global Accelerator
    
    Content Delivery network (CDN) - performance de leitura cacheando conteudo nas regiões de fronteira aws - 216 pontos no mundo - proteção DDoS integrada com Shield, AWS Web App. Firewall
    
    origins ( o q pode cachear)
        s3 bucket - distribuir arquivos e cachear nas fronteiras (edges) - segurança maior com cloudfront origin access control (OAC - substituindo Origin Access Identity (OAI))
            pode ser usado como ingress para upload de arquivos ao s3
        custom origin (HTTP) - Load Balancer - EC2 instance - S3 website (precisa habilitar site estatico) - qqr backend http
    
    cloudfront x s3 cross region replication
        cloudfront: rede global "de fronteiras" - conteudo cacheado com TTL - bom p conteudo estatico q precisa ser disponivel em todo lugar
        s3 crr: precisa configurar cada região - updates em tempo real - somente leitura - bom p conteudo dinamico em baixa latencia em só algumas regiões
        
    ALB como origem
        instancias EC2 precisam ser publicas (permitir ip publico de locais fronteira nos security groups) - cloudfront não tem conectividade privada com vpc
    
    GeoRestrição
        pode restringir por pais (allowlist e blocklist) - determinado por tabela de ip
    
    Classes de Preço
        custo varia por fronteira ao redor do mundo
        pode reduzir locais fronteira p reduzir custos
        all: todas regiões - melhor performance - maior preço
        200: maioria das regiões, menos as mais caras
        100: só regiões mais baratas - AMERICA DO NORTE/EUROPA
    
    Invalidação de Cache
        se atualizar a origem back end, cloudfront não saberá, só vai atualizar quando TTL acabar
        pode forçar atualização de cache parcial ou total fazendo cloudfront invalidation - todos arquivos (*) ou caminho (/images/*)
    
    Global Accelerator
        as vezes acesso passa por muitos servidores, aumentando risco e latencia
        Unicast: cada servidor tem um ip
        Anycast: todos os sevidores tem o mesmo ip e cliente é roteado para mais próximo
        
        Global accelerator usa anycast p rotear p aplicação usando locais fronteira direto sem passar por tudo q é servidor
            2 anycast ip são criados p aplicação - funciona com IP elastico, ALB, NLB, pode ser publico e privado
            trafego é mandado pela rede interna aws
        
        performance consistente - ip estatico - roteamento inteligente para menor latencia e evita falhas
        Health Check global nas aplicaçẽos e failover menor que 1 minuto para não saudaveis - bom p DR
        bom p segurança, integrado com aws shield contra DDOS
        
        diferente de cloudfront, usa fronteiras p ir direto a app ao invés de ir de fronteiras a fronteiras

AWS Storage Extras

    AWS Snow
        aparelhos seguros q coletam e processam dados em fronteiras e migram dentro e fora da aws
        migração:
            mais rapido q transferencia por rede, sem limite de banda, sem custo de rede, sem instabilidade - se leva mais de uma semana, usar snow
            snowcone: peqwueno portavel seguro resistente a condições extremas - usado onde snowball não cabe - precisa usar bateria e cabos proprios
                8tb de HDD, tem outra versão com 14TB de SSD
                pode ser usado para aws via fisica/offline ou usando internet com aws datasync
            snowballEdge:move tb ou pb, paga por job de transferencia - compativel com s3 - storage optimized (80 TB de HDD para block volume e objetos compativeis com s3)
                40 vcpus, 80 gb ram, 80 TB
            snowmobile: é um caminhão de verdade (1 EB - 1000000TBSSS) - cada 1 tem 100PB e é usavel em paralelo - seguro, temperatura controlavel, gps24/7, cameras tempo todo
                usar quando transferir mais de 10pb
        edge Computing:
            processar dados criados em localizações fronteira tipo caminhão, mina de minerais, barcos - conectividade limitada, sem acesso ou sem poder de computação
                magine learning, transcode media streams - se precisar, pode mandar de volta p aws
            snowcone: 2cpus, 4gb de ram, usb-c
            snowballEdge: compute optmized (42 TB de HDD para block volume e objetos compativeis com s3)
                104 vcpus, 416 gb ram, GPU, 28 TB NVMe ou 42 TB HDD - 16 nos de cluster de storage
                
        todos tem opção de deploy a longo prazo (1 a 3 anos com desconto)
            
        como usar: pedir device da aws - instalar client/aws opshub nos servers - conectar no servers e copiar usando client - enviar quando terminar
            dados vão parar num s3 e snowball é completamente formatado
            
        AWS OpsHub - facilitar acesso sem ser por linha de comando
            
    Snowball into Glacier - não dá p ser direto - usar s3 com lifecycle policy    

    Amazon FSx
        sistemas de arquivo 3rd party de alta performance como serviço completamente gerenciado aws
        Lustre, Windows file server, NetApp ONTAP, OpenZFS
        
        FSx Windows File Server
            suporta SMB e NTFS - integra com active directory, ACLs, user quotas - pode montar em ec2 linux - 
            suporta namespaces do microsoft distributed file system (DFS, grupos de arquivos espalhados em multiplos fs)
            
            escala até 10s de gb/s milhões de IOPS, 100s de PB de dados - HD e SSD - pode ser acessado on premises via vpn ou direct connect - pode ser multi AZ (disponibilidade)
            backup diario em s3
            
        Lustre
            sistema distribuido para larga escala de computação - linux + cluster
                machine learning, high performance computing, video processing, financial modeling, automação de design de eletronicos
            escala até 100s de gb/s milhões de IOPS, 100s de PB de dados - HD e SSD - pode ser acessado on premises via vpn ou direct connect
                tem ssd e hdd - integra transparente com S3, podendo ler e escrever nele
                
        NetApp ONTAP
            compativel com NFS, SMB, iSCSI
                linux, windows, mac os, vmware cloud, amazon workspaces e appstream, ec2, ecs, eks
            mover trabalhos rodando em ONTAP ou NAS para AWS
            auto scaling de armazenamento - snapshots de replicação, compressão de dados, e deduplicação - clonagem instantanea para testes
        
        OpenZFS
            compativel com nfs - mover trabalhos em nfs para aws
                linux, windows, mac os, vmware cloud, amazon workspaces e appstream, ec2, ecs, eks
            boa permormance - auto scaling de armazenamento - snapshots de replicação, compressão de dados, e deduplicação - clonagem instantanea para testes
        
        File System deployment options
            scratch - temporario, não replicado, rápido (6x mais rapido q storage convencional) - processamento de curto termo, menor custo pq não tem replica
            persistent - longo prazo, replicado no mesmo AZ, se falha, tudo é restaurado em minutos transparentemente - usar p dados sensiveis e processamento a longo prazo
        
    Storage Gateway
        hybrid cloud para armazenamento - parte em nuvem, parte onpremises - pode ser por varios motivos como compliance, migrações longas, segurança etc
        
        é uma ponte entre dados onpremises e cloud
        usado p DR, backup e Restore, tiered storage, cache on premises e acesso baixa latencia
        tipos
            S3 File
                https - pode ser usado com lifecycle policy para arquivar em glacier - nfs e smb - mais recente é cacheado no gateway                
                buckets usam IAM para cada gateway - integração SMB e Active Directory para autenticação
            FSx File
                acesso nativo para windows file server - cache local para dados acessados frequentemente (principal razão p usar esse gateway) - active direcory, ntfs
            Volume
                block storage protocol iSCSI com s3 - snapshot para restaurar dados on premises, volumes cacheados de baixa latencia, volumes todo on premises backups agendados no s3
            Tape
                fitas fisicas - backup na nuvem - virtual tape library (VTL) - s3 e glacier - compativel com opções de mercado - SCSI
                
        Hardware Applicance - se não tem hardware on premises, compra da amazon - file, volume, tape - backup diario em datacenters pequenos
        
    AWS Transfer Family
        serviço gerenciado completo para transferencia de e para s3 ou efs usando ftp
        ftp, ftps (ftp em ssl, encriptado), sftp (ftp seguro, encriptado)
        escalavel, confiavel, disponivel (multi-AZ) - paga por endpoint provisionado por hora + GB transferidos - guarda e gerencia credenciais
        integra com AD, LDAP, Okta, Amazon Cognito, etc - compartilhar dados, dados publicos, crm, erp
    
    DataSync
        move dados mto grandes de e para on premises ou outras nuvems para aws(nfs, smb, hdfs, s3 api) - precisa de agente
        aws para aws (armazenamentos diferentes) - não precisa de agente
        pode sincronizar para s3 (todas classes, incluindo glacier), EFS, FSx
        replicação pode ser agendada por hora, dia ou semana - permissões e metadados são preservados - um agente pode usar 10gbps, pode por limite de banda
        pode usar snowcone on premises (vem com agente) quando não tiver banda
    
    Resumo
        • 53: Object Storage 
        • 53 Glacier, Object Archival 
        • EBS volumes Network storage for one EC2 instance at a time 
        • Instance Storage: Physical storage for your EC2 instance (high lOPS) 
        • EFS: Network File System for Linux instances, POSIX filesystem 
        • FSx forWindowv Network File System forVVindows servers 
        • FSx for Lustre: High Performance Computing Linux file system 
        • FSx for NetApp ONTAR High OS Compatibility 
        • FSx for OpenZFS: Managed ZFS file system 
        • Storage Gateway: 53 & FSx File Gateway.Volurne Gateway (cache & stored).Tape Gateway 
        • Transfer Family: FTP FTPS. SFTP interface on top of Amazon 53 or Amazon EFS 
        • DataSync Schedule data sync from on-premises to AWS, or AWS to AWS 
        • Snowcone / Snowball / Snowmobile: to move large amount of data to the cloud, physically 
        • Database: com queries e index
    
    
Desacoplamento - SQS, SNS Kinesis, Active MQ

    mensageria/middleware - comunicação entre serviços - pode ser sincrono ou assincrono/event based
    sincrono pode ser problema se carga for imprevisivel, se tiver picos de uso - nesse caso, desacoplar aplicações e deixar desacoplamento escalar
    sqs - fila/queue, sns - pubsub, kinesis - streaming - escalam independente de aplicação
    
    SQS - simple queue service
    
        produtores -mensagens-> SQS queue -poll-> consumidores
        
        standard queue - mais de 10 anos, velho - gerenciado, usado p desacoplar app
        vazão e numero de mensagens na fila ilimitado - mensagens tem retenção padrão de 4 dias com máximo de 14 dias - baixa latencia - limite de 256kb por mensagem
        pode ter mensagens duplicadas - at least once delivery, ocasionalmente - pode ter mensagens desordenadas - best effort ordering
        
        Produzindo mensagens
            produz usando sdk (sendMessage API) - persistida no sqs até retenção ou consumer consumir/deletar
        Consumindo mensagens
            consumidores (em ec2, lambda, onpremises) - poll SQS para mensagens (recebem até 10 de uma vez) - processam mensagem - deletam mensagem usando DeleteMessageAPI
            recebem mensagens e processam em paralelo - pode escalar horizontalmente para aumentar processamento
            
        Ex de uso em conjunto com ASG - pode ter um alarme em cloudwatch em cima de uma metrica de tamanho de fila, se subir alarme dispara e lança evento de escala para ASG
        ex de arquitetura
            -Req-> (front end app).ASG -message-> SQS -receiveMsg-> (back end processing app).ASG -insert-> s3 bucket
        
        Security
            encripta em transito usando HTTPS API, em repouso usando KMS keys, permite client side
            access controls permite politicas IAM para regular acesso a api SQS - tem policies proprias similares a s3 (util para acesso de outras contas)
        
        visibility timeout
            se mensagem é pollada por um consumidor, fica invisivel para outros consumidores - por padrão esse tempo de invisibilidade é 30s
            se não for processada nesse tempo, volta visibilidade - pode chamar api changemessagevisibility para pedir mais tempo
            se tempo de visibilidade é alto e consumer quebrar, reprocessar leva muito tempo - se baixo, aumenta chance de mensagens duplicadas
        
        Long Polling
            esperar mensagens chegar durante polling enquanto não tem mensagens - melhora latencia, diminui chamadas a api do sqs - pode ser de 1 a 20 segundos (20s preferivel)
            melhor q short poling - pode ser habilitado na fila ou na api usando WaitTimeSeconds
        
        FIFO queue - First in first out - diferente da standard - vazão limitada a 300 msg/s sem batch - 3000 msg/s com
            envia apenas uma vez - remove duplicados - mensagens consumidas em ordem - nome tem q terminar com .fifo
            
    SNS - Simple notification Service
        pubsub - produtor de eventos só manda mensagem para um topico sns - receptores se inscrevem no topico - todos assinantes recebem todas mensagems (tem recurso p filtrar)
        até 12.5M de susbscrições por topico limite de 100k topicos
        sns --publica--> assinantes (pode ser sqs, lambda, email, endpoint http...) - varios serviços aws podem mandar dados diretamente para sns(cloudwatch, lambda, budgets,asg,bucket, dynamo...)
        publicar usando sdk(criar topico, subscrição, publicar p topico) ou direct (app, endpoint, publicar no endpoint, funciona com ADM, ggoogle GCM, APNS)
        
        mesma segurança q SQS - suporta FIFO também        
        
        SNS + SQS fan out: publicar no sns e receber em todos SQS assinantes - desacopla, não perde dados, permite adicionar sqs de acordo com necessidade - cross region
            sqs tem q permitir escrita do sns nas politicas
            pode usar isso com s3 (s3 tem limitação q só pode um eventtype com um prefixo)
            pode fazer isso com kinesis também
            SNS FIFO + SQS FIFO é possível tb
            
        pode filtrar usando politica json mensagens que manda para os assinantes do sns - possivel separar mensagems (ex mensagens de cancelamento, de compra, etc)
             
    Kinesis
        coleta processa e analisa stream de dados (logs, metricas, clickstream - rapido e em tempo real é o critério)
        
        Kinesis Data Streams - caputra processa e armazena streams de dados
            producers podem ser mtas coisas, como app, SDK, KPL, Agent - produzem registros (chave de partição/data blob de até 1mb) - 
            feito de shards que podem ser escalados - produzem registros (chave de partição/numero de sequencia/data blob de até 2mb / s ou 2mb/s por shard (enhanced) - 
            cosumidores podem ser app, lambda, firehose ou data analytics 
            
            retenção entre 1 e 365 dias, pode reprocessar dados, dados inserido imutaveis não deletaveis, mesma partição vai p mesmo shard
                modo provisionado: numero de shards escolhido, escalado manual ou por ai, cada shard tem entrada de 1mb/s (1000 /s) e saida 2 mb/s (classico ou fan out) - paga por shard por hora
                on demand: não precisa provisionar, automatico, 4mb/s - escalavel com metrica de uso dos ultimos 30 dias - paga por stream por hora por giga
                segurança: deployado numa região, acesso por IAM, encriptação em voo HTTPS, descanso KMS, pode ser client side
                latencia 200 ms
                
        Kinesis Data Firehose - carrega stream de dados nos data store AWS
            pode ter dados transformados por lambda e escreve em batch em destinos (AWS(S3, redshift (copy through s3), opensearch), splunk, datadog, mongo..., custom endpoint http)
                pode ter backup no s3 de tudo ou falhas
            totalmente gerenciado, serverless, auto escala - quase tempo real, intervalo de buffer (0 a 900s) - tamanh minimo buffer 1mb
        Kinesis Data Analytics - analisa data streams com SQL ou Apache Flink
        Kinesis Video Streams - caputra processa e armazena streams de videos
        
    Ordenamento Kinesis vs SQS FIFO
        mesma chave de partição sempre vai no mesmo shard - 1 consumer por shard
        no sqs, se não tiver group id, é consumido só por um consumer
        kinesis é melhor p ordenar por shard e dados maiores, sqs fifo é melhor por numero dinamico de group/id consumer
        
    Amazon MQ
        apps on premises podem usar protocolos abertos como MQTT, AMQP, STOMP, etc... - então ao invés de mudar tudo p usar protocolos SQS e SNS, Amazon MQ dá suporte para activeMq e RabbitMq
        gerenciados - não escala tanto quanto SNS\SQS - tem features de SQS e SNS e pode ser multiAZ com failvoer
        alta disponibilidade - mestre escravo - usa EFS nas duas instancias em AZ diferentes
        

Containers AWS: ECS, Fargate, ECR, EKS

    ECS
        elastic container service - docker da aws
        
        EC2 Launch Type
            containers ecs na aws são ECS tasks em ECS clusters - Ec2 Launch Type - voce provisiona e mantem infra (EC2) - ec2 roda ecs agent para se registrar no cluster - aws sobe e desce containers
            Fargate launch type - serverless, não provisiona infra, só cria definição de task, aws roda se baseando em cpu / ram q precisa

        IAM Roles p ECS
            EC2 instance profile p launch type ec2 - usado pelo ECS agent para fazer chamadas ao serviço ECS, mandar logs p cloudwatch , pegar imagem docker do ECR, referenciar dados secretos ou params.
            ECS Task Role: role por task - fargate e ec2 - cada role pode ser usada para serviço ECS diferente
            
        Integração com Load balancer
            ALB, NLB (apenas recomendado para casos q precisa de muita performance, ou q usa AWS Private Link) - não recomendado com CLB pq não pega fargate
            
        Data Volumes (EFS)
            montar EFS nos ECS tasks - funciona com fargate e EC2 launch types - EFS é multi AZ logo aplicações ECS q o usam tb podem ser
            Fargate + EFS = serverless
            
        ECS Auto Scaling
            por cpu - por memoria RAM - por request no ALB
            por target - valor de metrica do cloudwatch, por step - baseado em alarme de cloudwatch, scheduled - baseado em data/hora (mudanças previsiveis)
            autoscaling de ECS(task) é diferente de autoscaling de EC2(instance) - autoscaling do fargate é mais fácil de configurar pq é serverless
            
            autoscaling ec2 usando ec2 launch type - acomoda serviço ECS escalando instancias EC2
                por grupo - baseado em cpu - adiciona isntancias ao longo do tempo
            ECS capacity provider (recomendado)
                provisiona e escala automaticamente tasks ecs - pareado com auto scaling group - adiciona instancias quando capacity é pouco (CPU, RAM, Etc)
            
        ECS Solution Architecture
            ecs task invoked by event bridge - eventbridge pode ter regra de rodar task ecs (tem escs task role q deixa usar s3 e dynamo por exemplo)
            ecs invoked by event bridge schedule - 
            sqs queue - tasks consumem fila e processam (auto scaling pode ajudar)
            ecs - event bridge intercepta tasks paradas usando event bridge - analise de ciclo de vida
        
    ECR - elastic container registry
        gerencia imagens docker na aws - privado e publico - integrado com ECS, suportado por s3
        ec2 usando iam role consegue manipular imagens docker - armazena na ec2 - suporta scan de vulnerabilidade de imagem, versionamento, tags, ciclo de vida de imagem, etc
        
    EKS
        elastic kubernetes service - cluster k8s gerenciados - alternativa a ecs, mesmo objetivo mas api diferente
        K8s é open source, EKS não - geralmente containers são docker
        modos ec2 (worker nodes) e fargate (serverless containers)
        
        usado p migrar k8s de premises ou outra nuvem - k8s é agnostico a cloud, funciona em qqr uma)
    
        Node types
            gerenciado por aws- cria e gerencia EC2 (nodes) - ASG gerenciado por EKS - suporta instancias on demand ou spot
            autogerenciado- nodes criados por usuario e registrados no EKS e gerenciado por ASG - pode usar AMI otimizado - suporta on demand e spot
            fargate - serverless - sem manutenção ou gerencia de node
            
        data volumes - precisa especificar storage class no eks cluster - usa container storage interface CSI compliant driver
            ebs, efs (funciona com fargate) , fsx lustre, fsx netapp ontap
        
    App Runner
        serviço facilitador de deploy escalavel de api e web - não precisa saber nada de infra - começa com codigo fonte e container, configura detalhes como vcpu, healthcheck, ram, asg, etc
        automaticamente constroi e deploy app - acesso a vpc, filas, dbs, cache - auto escalavel, disponivel, LB, encriptação, 
        
        
Serverless

    paradigma sem gerencia de servidores - deploy de codigo / função - function as a service inicialmente - serverless agora é tudo gerenciado sem servidores
    lambda - dynamodb - cognito - api gateway - s3 - sqs - sns - kinesis data firehose - aurora serverless - setp functions - fargate
    
    Lambda
        multi az via replicação - deployar lambda nas regiões desejadas
        funções virtuais - sem servidores - limitado por tempo - execuções curtas - sob demanda, só roda quando invocado - autoscale
        pago por request/compute time - gratis 1M e 400 gb/s de compute time - integra com muitos servicos AWS - suporta muitas linguagens - monitoria facil via cloud watch
        facil de obter mais recursos por funções - até 10 gb de ram - aumentar ram aumenta cpu e rede
        
        nodejs - python - java 8 ou 11 - c# dotnet core - golang - ruby - c#/powershell - custom runtime api (comunidade, ex rust) - lambda container image (imagem precisa implementar api runtime lambda)
            é melhor ecs/fargate para rodar imagens padrão docker se não implementar api runtime lambda
            
        ex serverless thumbnail creation - imagem -> s3 -event notification-> lambda gera thumb -push-> bucket s3
                                                                                                -push-> metadados no dynamoDb
        
        ex serverless cron job - eventbridge dispara evento a cada 1h - lambda
        
        gratis 1M e 400 gb/s de compute time - depois 0.2$ por M de request, e duração paga por ms a mais - quanto mais ram, mais request por ms - consome tempo mais rapido?
        tempo de iniciação só na primeira execução
        
        limites lambda - por região - 128mb a 10gb(incremento de 1mb) - maior tempo de execução 15 minutos - variaveis de ambiente 4kb
            disco entre 512mb a 10gb - concorrencia 1000 (pode aumentar)
            tamanho - 50mb comprimido, 250 não comprimido
            
        SnapStart - aumenta performance até 10x sem custo para java 11 e maior - função sempre tá preinicializada - usa snapshots para reduzir latencia
        
        Lambda At the Edge
            edge function - lambda em cloudfront - roda perto dos usuarios - minimiza latencia
            
            cloudfront functions
                leves - em javascript - alta escala, sensivel a latencia, CDN customização - startup sub ms - milhão por segundo de requests
                só viewer request e viewer response
                max memory 2mb - package size 10 kb - sem acesso a rede, sistema de arquivos, e request body - tem free tier, preço costuma ser 1/6th do @edge
                
                cache key normalization (transforma dados para criar chave otimizada de cache)
                header manipulation (modifica headers em request ou response)
                url redirects ou rewrites
                request authentication e authorization (validar e criar tokens para permitir ou negar requests)
                
            lambda@Edge
                nodejs ou python - milhares por segundo - muda resposta cloudfront - viewer request/response, origin request/response
                    viewer - depois de cloudfront receber request, origin - antes de cloudfront receber request
                criar funções em uma região e cloudfront replica para seus locais aws
                max memory 128mb até 10gb - package size 1 a 50 mb - com acesso a rede, sistema de arquivos, e request body - sem free tier, cobrado por request e tempo
                
                tempo maior de execução - cpu e memoria ajustaveis - pode usar bibliotecas externas - usar sdk para acessar outros serviços aws
            
            serverless - deploy global - usar para customizar CDN - pago por uso
                app dinamico fronteira, SEO, routing, AB testing, image transformation, priorization, analytics, etc
            
        Lambda em VPC
            por padrão, lambda roda fora de vpc propria (mas da amazon mesmo assim) - não pode acessar por padrão outros recursos na sua vpc
            pode rodar em vpc - definir id de vpc, subnets e grupos de segurança - lambda terá ENI (elastic network interface) nas subnets
            
            lambda com acesso a banco causa stress por conta de conexões sendo criadas e apagadas de acordo com a vida do lambda
                criar rds proxy - abstração no meio - melhora escala dividindo conexoes - aumenta disponibilidade em 66% - melhora segurança forçando uso de IAM e secret manager
                
                lambda precisa ser depoyado no vpc pois proxy rds nunca é acessivel publicamente
    
        Invocando Lambda de RDS e Aurora            
            permite chamar lambda de dentro de instancia de banco - processa dados dentro do db - suportado por rds postgresql e aurora mysql
            precisa permitir trafego de saida para lambda do db (public, nat, gw, vpc endpoints) - precisa de permissões IAM proprias
            diferent dos RDS event notifications onde não se tem informação dos dados que causam os eventos - tem eventos de snapshot, grupo de parametros, sec.group, proxy, custom engine
                tempo quase real - até 5 min de atraso - notificações podem ir p eventbridge ou sns
        
    DynamoDB
        gerenciado, disponivel, replica em multiplos AZ - proprietario AWS - nosql com suporte a transação - distribuido - escala a milhões de requests por segundo, trilhões de linhas
            100s de TB de armazenamento
        performatico (até 10ms) - integrado com IAM para segurança, autorização, admnistração - custo baixo autoescalavel - smpre disponivel sem manutenção nenhuma
        categorias Standard p acesso frequente e infrequent
        
        feito de tabelas - não precisa criar banco de dados - tabela tem pk (tempo de criação de tabela) - numero infinito de items (linhas)
        cada linha pode ter atributos (podem ser adicionados ao longo do tempo e pode ser nulo) - 400kb poor linha
        suporta dados de tipo
            escalar - string, number, binary, boolean, null
            document - list, map
            set - string set, number set, binary set
        DYNAMO permite evoluir schemas de forma rapida !!!!
        
        modos de capacity de leitura e escrita
            provisioned mode (default)
                especifica numero de read/writes por segundo - planejar capacity de antemão - paga por unidade de capacidade de leitura / escrita (RCU / WCU - são desacoplados e pode mudar só um) - 
                possivel adicionar autoscaling baseado em RCU/WCU
            on demand mode
                read/write escalam automaticamente de acordo com carga de trabalho - não precisa planejar capacity - paga pelo uso, mais caro - 
                otimo para cargas IMPREVISIVEIS, ou com SURTOS AGUDOS de uso
        
        DynamoDb Accelerator (DAX)
            cache gerenciado transparente disponivel em memoria para dynamo - cache de dados para leitura para evitar "congestionamento"
            microsegundos de latencia para dados cacheados - funciona na api do dynamo, transparente a codigo
            usar dax e não elasticache pq é feito p dynamoDB - cache de objetos para queries e scan - p agregados melhor usar elasticcache
            
        DynamoDb Stream Processing
            stream ordenado de modificações em uma tabela a nivel de item (crud) - reagir a novo usuario - analitics em tempo real - inserir em tabelas derivadas - replicacao cross regiao - lambda
            dynamoDb Streams: retenção de 24h - numero de consumidores limitados - processa usando gatilho de lambda ou adapter de kinesis
            kinesis data stream (novo): 1 ano de retenção - maior numero de consumidores - processar usando lambda, kinesis data analitics/firehose, aws glue, streaming etl...
            
        Global Table - tabela replicadas em duas vias - baixa latencia em multiplas regiões - replicação ativa-ativa - dynamodb streams é pre-requisito
        TTL - automaticamente deleta items depois q expira
        backups p DR - point in time recovery - até 35 dias - recuperação cria nova tabela - não afeta performance nem latencia - serviço AWS de backup permite maior controle e cross região
        Integração com s3 - pode exportar tabela no s3 - tem q habilitar point in time recovery - query nesses dados no s3 usando aws athena
            não afeta latencia nem RCU - performa analise de dados em cima do dynamo - mantem snapshots p auditoria - ETL no s3 antes de reimportar p dynamo - exporta em DynamoDB JSON ou ION
            importa do s3 em CSV, DynamoDB Json ou ION, não custa WCU - cria nova tabela
    
    API Gateway
        client-rest -->> API Gateway -- proxy requests->> lambda --CRUD-->> Dynamo
        API Rest publica e acessivel sem infraestrutura para gerenciar
        suporte a websocket - versionamento de api - ambientes diferentes - sergurança e autenticação e autorização - chave de api, throtle de requests
        integração swagger e open api - transformar e validar requests - gerar especificaçãoes de sdk e api - cachear respostas de chamadas de api
        
        integrações de auto nivel
            lambda - jeito facil de expor lambda e ter app serverless
            http - expor endpoint no backend  - ex api interna, ALB sem ser aws - adicionar cache, auth, chaves de api, etc
            aws service - qqr api aws pode ser exposta pelo api gateway - throtle, auth, deploy publico
            
        endpoint types
            edge optmized - para clientes clobais - usa fronteiras do cloudfront - melhora latencia - gateway ainda assim está em apenas uma região
            regional - clientes na mesma região - pode combinar manuialmente com cloudfront para mais controle de cache e distribuição
            private - apenas acessado na vpc usando endpoint de vpc de interface (ENI)
    
        security
            IAM roles (app internas)
            cognito (apps externos ex usuarios mobile)
            custom auth (lambda)
            
            custom damin name http através de amaazon certificate manager (ACM) - precisa de CNAME ou registro A-alias no route 53
            
    Step Functions
        workflow visual serverless para orquestrar funções lambda
        paralelismo, timeouts, sequenciamento, integra tb com ec2, api gateway dynamo, sqs, ecs... - permite implementar permissão humana        
        
    Cognito
        identidade para web ou mobile
        
        cognito user pools (CUP) - funcionalidade de logar para usuarios mobile -  com api gateway e alb
            db serverless de usuarios web e mobile - login simples (user/pass) - password reset - verificação email e telefone - MFA - identidade federada
        cognito identity pools - credenciais aws para acesso direto a recursos aws - identity provider para cognito user pools (ex identidade federada)
            credenciais aws temporarias - usuarios cognito ou externos - acessa serviços aws ou por api gateway - politicas IAM são definidas no cognito e podem ser customizadas por userId p granularidade
            pode ter IAM padrão para facilitar - pode usar p limitar leitura no dynamo por ex ("dynamdb:LeadingKeys": {"$cognito-identity.amazonaws.com:sub"}
        cognito vs iam: centenas de usuarios, usuarios mobile, autenticar com SAML
        

Serverless Architecture
    mytodolist
        rest - https - serverless - interagir direto com s3 - autenticar via serverless - escrever todos e ler (mais ler) - db deve escalar e aguentar bastante leitura
        
                         ------permissões/policy-----s3
                        /
        mobile client--|-----api gateway (com cache de resposta)----lambda----dax cache----dynamo
                       \         |
                        \        |(autenticar)
                         \       |                 
                          ----cognito|--------------(gerar credenciais temporarias)---STS
    
    myblog
        escalar global - pouco escrito muito lido - maior parte é estatico, mas tem api rest dinamica - cache onde possivel - novos usuarios recebem email - fotos geram thumb
        
                       cloudfront -----origin access control(OAC)---s3 (policy só permitindo leitura de cloudfront)        
                      /
        mobile client|--rest https--api gateway---lambda----dax----dynamo
                     \
                      cloudfront--OAC----s3----lambda---(thumb)---s3-|---Sqs
                                                                     \---Sns
    
    microservices - alguns dos problemas de microserviços são resolvidos pelo paradgma servless
        
                /-DNS (Route 53)             /------Load Balancer---ECS------Dynamo
        users---|----------------------------|------Api gateway-----lambda----elasticache
                                             \------Load Balancer----(Ec2)ASG----RDS
            
    software update distribution
        distribuir atualização periodicamente via ec2 - caro quando sai versão nova - não quer mudar app, mas quer otimizar custo CPU
        
        users ----cloudfront----AZs-----ASG(AZs(Ec2(EFS)))
        
        cloudfront pois não muda arquitetura, é serverless e escala sozinho, aliviando custo ASG - cacheia nas fronteiras instalador de update
    
        
Databases na AWS

    criterios: carga em leitura/escrita - vazão - evolução de schema - escalabilidade - tamanho e retenção - tamanho médio - acesso - durabilidade - latencia - concorrencia - queries - função - custo
    tipos
        rdbms - joins
        nosql - sem joins nem sql, mais flexivel
        object store
        data warehouse - analytics, BI
        search - texto livre, busca não estruturada
        graph - relações entre dados
        ledger
        time series
        
        
    RDS - usado para transações, queries sql, dados relacionais        
    Aurora - igual a rds, porem mais performatico, mais flexivel, com menos manutenção, mais features out of the box
    ElastiCache - para usar precisa de mudar codigo, logo se não puder, não usar
    DynamoDB - documentos pequenos em torno de 100 a 400 kb, distribuido, serverless, cache
    S3 - bom p menos objetos grandes que muitos pequenos, arquivos estaticos, website host
    DocumentDB - versão aurora de mongoDb
    Neptune - graph db, tipo redes sociais - detecção de fraudes, motor de recomendação, wikis
    Keyspaces for apache cassandra - cassandra na nuvem, IoT, time-series
    QLDB - ledger db - dados imutaveis, transações financeiras, mais performance q blockchain, tem sql e componente central de autoridade
    Timestream - curva? - trilhões de dados, 1000s mais rapido q rdbs - IoT, aplicações operacionais, analytics em tempo real


Data & Analytics

    Athena
        serverless query service p analise de dados no s3 - sql (presto) - csv, json, orc, avro e parquet - 5$ por TB de dados escaneados - usado com quicksight para relatorios e dashboards
        BI, analytics, reporting, logs, etc - analisar dados no s3 serverless -> athena
        usar dados com colunas para economizar custos e aumentar performance (ORC, Parquet) - usar glue p converter p orc ou parquet - comprimir dados - particionar datasets
        usar arquivos grandes para minimizar overhead
            ex de particionamneto: s3://bucket/flight/parquet/year=1999/month=1/day=1
        query federada - roda queries em rdbms, nosql, e outros (aws ou premises) - data source connectors em lambda para traduzir queries para outras fontes de dados
        
    RedShift
        baseado em postgresql, não usado para OLTP e sim para OLAP - mais perfonrmance q outros data warehouses, escala a PBs de dados
        baseado em colunas ao inves de linhas - motor paralelo de query - paga por instancias provisionadas - sql - integra com quicksight, tableau e outros
        queries, agregações, joins mais rapidos que athena por conta de indices - usar ao inves de athena se tiver joins ou mais complexidade
        cluster tem no lider que recebe query e agrega resultados e nós computacionais q fazem queries e retornam p lider - pode provisionar antes o tamanho dos nós
            pode usar instancias reservadas para diminuir custo
        tem multi AZ para alguns tipos de cluster. para AZ unico, usar snapshots (incrementais, armazena no s3) - restaura em novo cluster
        automatico - 8h ou 5gb novo snapshot - retenção pode ser automatica por agendamento ou manual até apagar
        pode copiar snapshots automaticamente para cluster em outra região (DR)
        inserts "Grandes" são melhores para redshift
        
        spectrum - analisar dados s3 sem carregar do s3 - tem q ter cluster pronto - ao iniciar, milhares de nós spectrum analisam resultado
        
    OpenSearch
        sucessor do elasticSearch
        dynamo só tem query por pk ou indice, opensearch tem por qqr campo, mesmo quando é parcial e não completo o match - muito usado como complemento a outro banco
        managed ou serverless - não suporta sql nativo, tem plugin q habilita - integra com kinesis data firehose, aws IoT, cloudwatch logs
        segurança via cognito, IAM, KMS, TLS - vem com opensearch dashboards (visualização)
        
        ex Dynamo
            CRUD --->DynamoDB table ---> DynamoDB Stream ---> Lambda ---> OpenSearch ---> M5 --> DynamoDB (item completo) ----> usuario
        
    EMR
        elastic map reduce - cluster hadoop - big data em AWS - clusters podem ter centenas de EC2
        tem ferramentas necessárias como Spark, HBasem Presto, Flink... - auto escala, integra com instancias spot
        no mestre - gerencia cluster, coordena, HC, executa muito tempo
        no core - armazena dados e faz tarefas - execução longa
        no de tarefa (opcional) - faz tarefas - spot
        pode cobrar - on demand (confiavel, previsivel, não é terminado) - reservado (minimo de 1 ano, economica - EMR usa se disponivel) - Spot (baratos, podem ser terminados, menos confiavel)
        cluster pode ser longo ou temporario
        
    QuickSight
        BI - dashboards interativos - serverless - rapido, autoescalavel, embutivel, preço por sessão - integra com RDS, Aurora, Redshift, S3... 
        computação em memória usando spice engine se dados importados no quicksight - tem segurança baseada em coluna - oculta p quem não tem permissão
        integra tb com teradata (on premises JDBC), salesforce, jira - importa csv, xls,xlsx, json, tsv, elf, clf
        tem usuarios (edição standard) ou grupos (enterprise, mas não são usuarios IAM)
        dashboard - snapshot somente leitura de analise - pode compartilhar - preserva config e parametros e ordenação
            compartilha com usuarios e grupos - para compartilhar tem q publicar primeiro - quem ve dashboard tb acessa dados q o compoem
            
    Glue
        ETL gerenciado, serverless - de rds, s3,... para redshif, parquet
        ex converter p parquet
        
        s3 put >--> Input s3 bucket >---import csv---> glue etl >---parquet ---> output s3 bucket >---analyze---> athena
                        V                                  ^                                  
                        |                                  |
           event notification on s3 put             trigger glue etl job
                        |                                  |
                        \-----------------------------> lambda/event bridge
            
        glue data catalog - cataloga datasets - roda glue data crawler e e escreve metadados no glue catalog - ai tem todas as tabelas, dados e metadados para etl
            redshift, athena e emr se beneficiam disso
        glue job bookmarks - previne reprocessar todos dados
        glue elastic views - combina e replica dados atravez de multiplos data store usando sql, serverless, materialized view - monitora mudanças nos bancos - sem codigo necessario
        glue studio - GUI para glue
        glue streaming etl - usando spark - compativel com kinesis, kafka, msk (managed kafka)
        
    Lake Formation
        cria datalake (armazenado no s3) - local central para todos os dados para analitics - gerenciado - em regra leva meses, mas lake formation leva dias
        descobre, limpa, transforma e inser dados no data lake - automatiza passos manuais complexos e remove duplicadas usando transformações ML (machine learning?)
        feito em cima do glue - acesso granular para apps, coluna e linha - combina dados estruturados e não estruturados - OOTB s3, rds, rdmbs, nosql ...
        centralized permissions - acesso granular controlado para colunas e linhas
        
    Kinesis Data Analytics
        para SQL - entra de kinesis datastreams/firehose - kinesis data analytics - sai para kinesis data streams(lambda,apps), kinesis firehose (s3,redshift, outras saidas do firehose)
            tempo real - dados de referencia do s3 para enriquecimento - gerenciado, serverless - autoescala - paga por consumo - metricas e dashboards em tempo real, analise de series de tempo
        para apache flink/amazon managed service for apache flink - entra de kinesis data streams ou amazon msk
            roda em cluster gerenciado na aws - provisiona recursos, computação paralela, autoscale - backups (snapshots em checkpoints) - usa recursos do flink - não le do firehose, 
                usar kinesis  analytics for sql no lugar
            
    MSK
        Managed Streaming for Kafka - alternativa a kinesis - cluster gerenciado kafka no aws - permite criar, atualizar apagar clusters e MSK cria e gerencia brokers e zookepers
        deploy no VPC, multi AZ - recuperação automatica de falhas de kakfa - dados guardados indefinidamente em volumes EBS - pode ter modo serverless
        produtores e consumidores adaptam entradas e saidas ((precisa codar))
            consumidores podem ser kinesis analytics .. for flink, glue, lambda, ou ecs,ec2,eks rodando codigo codado
        Kinesis Data Streams 
            1 mb - shards - shard split & merge - TLS in flight enc.- KMS at rest enc.
        MSK
            1 mb, mas pode ser mais - topicos e partições - pode adicionar partições somente a topicos - texto ou TLS enc - KMS at rest enc
        
    
    BigData Ingestion Pipeline
        ex de arquitetura
        
        IOT(0) -> Kinesis data streams - kinesis firehose(1) - Lambda e s3 ingestão- SQS - Lambda(2) - athena(3) - s3 report - redshift -/- quicksight 
        (0) - tempo real, (1) - todo minuto, (2) lambda dispara athena, (3) athena faz pull do s3 de ingestão
    

Machine Learning

    Rekognition
        achar objetos, pessoas, texto, cenas em imagens e videos - analise facial e busca facial - contagem de pessoas - banco de dados de rostos familiares
        analise de caminhos - esportes - moderação de conteudo (inapropriado ou inofensivo) - configurar nivel minimo de confiança para marcar itens ofensores
            A2I amazon augmented AI permite revisão por humano - integrado no rekognition
            
    Transcribe
        converte fala em texto automaticamente - deep learning asr (auto speech recognition) - rapido e preciso
        automaticamente remove dados sensiveis usando redaction - identificação automatica de idioma
        
    Polly
        converte texto para fala usando deep learning - apps q falam - usa lexicon (customiza pronuncia e entende "girias" como l33t e acronimos como AWS - Amazon Web Services) 
        SSML - speech synthesis markup language - mais customização, como enfase, fonemas, sons de respiro, ofegante, estilo jornalista de falar, etc
            parece html
        
    Translate
        tradutor - localiza conteudo e traduz volumes largos eficientemente
        
    Lex + Connect
        Lex - tecnologia por trás da alexa - ASR - reconhece intenção e interpreta texto - chatbot, callcenters
        Connect - recebe chamadas, cria fluxo de contato, integra com CRM - não paga antecipado, 80% mais barato q soluções de callcenters
        
        telefone ->chamada-> connect ->stream-> lex ->invoca-> lambda ->agendamento-> CRM
        
    Comprehend
        processamento de linguagem natural - gerenciado e serverless - machine learning p achar relações e insights em texto
        entender o negativo e positivo - usa tokens para analise de texto e partes de fala ? - organiza automaticamente coleção de arquivos texto por topico
        
        analisar emails p ver positivos e negativos, criar e agrupar artigos por topico
        
    Comprehend Medical
        detecta e extrai texto util em texto clinico não estruturado usando NLP (atestado, dispensa, exame, notas) - usa API detectPHI (protected Health information)
        
        ex
            s3 -> kinesis data firehose -> comprehend medical
            audio -> transcrive -> comprehend medical
        
    SageMaker
        gerenciado para construir modelos de machine learning - mais dificil de usar pois cria modelo ao invés de só usar modelo
        dificil de provisionar infra - sagemaker simplifica - modelo é feito para prever resultado
        para devs e cientistas de dados
        loop de modelo - dados de entrada - refinar modelo - dados saida - refinar modelo ... repete
        
    Forecast
        gerenciado - previsões precisas - agiliza previsões de meses para horas - mais eficaz q analisar dados
    
    Kendra
        gerenciado usando ML para pesquisar documentos - extrai dados de dentro de documento (txt, pdf, word, html, powerpoint...)
        cria indice de conhecimento e ai tem suporte a busca por linguagem natural - aprende com feedback e interações - possivel refinar resultados por varios criteiros
    
    Personalize
        serviço q usa ML para recomendações personalizadas - usado em amazon.com
        
    Textract
        extrai texto, letra de mão e dados de docuemntos escaneados usando AI e ML - extrai de formularios, tabelas, pdfs, imagens, etc
    
Monitoria e Auditoria

    CloudWatch Metrics
        metricas para todos serviços aws - monitoria tudo na conta (ex cpusize, bucketsize, networkIn) - metrica tem namespace e atributo dimension (até 30 dimensions por metrica)
        metricas tem timestamp - dashboard de metricas - pode ter metrica customizada
        
        stream de mtricas para destino, com quase tempo real e baixa latencia - 3rd party service (splunk, datadog, etc) ou kinesis data firehose e seus destinos (s3, redshift, opensearch)
            opção de filtrar metricas para stream de subconjunto delas apenas
    
    Cloudwatch Logs
        log groups - nome arbitrario representa app - contem log streams
        log stream - instancias dentro de app / log files / containers - pode definir politica de expiração(nunca, 1 dia a 10 anos, etc)
        pode mandar para s3 (export) , kinesis datastreams/firehose, lambda, opensearch - encriptado por padrão - pode ter kms com chave propria
        
        fontes
            sdk, cloudwatch logs agent, cloudwatch unified agent
            beanstalk, ecs, lambda, vpc, api gateway, cloudtrail por filtro, route53 (queries no dns)
        cloudwatch log insights - queries em logs, exporta resultado e poe em dashboard para ser executado de novo - muitos exemplos
            descobre campos em serviços aws e json - pode consultar logs em contas diferentes - motor de query, não de tempo real
        cloudwatch subscriptions - tempo real para processamento e analise - destinos kinesis data stream/firehose, lambda - possivel filtrar qual log vai p destino
        
        graças a filtros de subscrição, é possivel ser multi conta(KinesisDS,KinesisDF) e multi região - agrega tudo em um destino só            
        live tail - 1h gratis por dia
    
    Cloudwatch Agent & Log Agent
        por padrão ec2 não manda log p cloudwatch - precisa de agent com permissão IAM para mandar. pode ser onpremises tb
        para servidores virtuais
        
        Agent - mais velho - manda apenas p cloudwatch logs
        Unified Agent - novo - coleta metricas de sistema, como ram, processos, etc - manda logs p cloudwatch logs - config central usando ssm parameter store
        
        cpu granular (ativo, idle, steal, etc), disk, diskIO, ram, netstat, processes, swap... ootb - as mais simples
        
    Cloudwatch alarms
        dispara notificação para metrica - várias opções (max, min, %, etc) estados OK, INSUFICIENT_DATA, ALARM - periodo (tempo em segundos para avaliar metrica), pode ter resolução alta (10 em 10s...)
        
        alarm targets
            rebootar, parar, ou recuperar EC2 - disparar autoescala - mandar mensagem SNS (e dai d p fazer tudo)
        composite alarms
            cada alarme usa uma metrica - composite combina varios alarmes usando AND e OR - reduz "ruido" com alarmes mais precisos
        
        ec2 instance recovery
            instance status - verificar EC2 VM
            system status - verifica hardware abaixo da vm
            recovery - mesmo privado, publico, elastic ip, metadata, placement group
            
        pode criar alarme em cima de filtro de metrica - pode testar usando CLI
        
    EventBridge (anteriormente CloudWatch Events)
        cronjobs, eventos que reagem a ação de serviço (ex sign in em root dispara notificação em topico sns) - pode combinar com cloudtrail e interceptar todas as chamadas de api
        pode filtrar por condições - gerado json com informações do evento
        default event bus, partner event bus (SaaS) - integra evento de aplicações terceiras suportadas, custom event bus - receber eventos de aplicações
        é possivel acessar cross account usando politicas baseadas em recursos
        pode arquivar eventos (todos/filtrados por periodo/indeterminado) - pode reenviar eventos (replay)
        
        schema registry
            event bridge consegue descobrir schema analisando eventos q passam por ele - gera codigo para app pronto para lidar com schema descoberto
            versionados
            
        Resource-based policy
            gerencia permissão de "bus" - permite nega eventos de outra região ou conta - agregar eventos de toda organização em uma só conta/região
            sem politica definida, só dono do bus pode mandar eventos para bus
            
    Cloud Watch Insights & visibilidade operacional
        container insisghts - metricas e logs para containers (ECS, EKS, K8s em Ec2, Fargate (ECS,EKS))
            em eks e k8, cloudwatch insisghts usa versão conteinerizada do agent para descobrir containers
        lambda insights - monitoria de lambda - agrega, resume, dados de hardware, cold starts, shutdowns, provido via lambda layer
        contributor insights - timeseries de contribuintes - achar o q impacta performance - funciona para qqr log AWS - pode criar regras do zero ou começar de exemplos
            tem metricas para outros serviços AWS OOTB
        application insights - dashboards automatizados para isolar erros constantes - algumas tecnologias apenas - pode usar outros recursos aws
            feito com sagemaker - aumenta visibilidade de saude de app - alertas e resultados enviados para EventBridge e SSM OpsCenter
            
    Cloud Trail
        governança, compliance e audit para conta - habilitado por padrão - historico de eventos /chamadas de api dentro da conta por CLI, SDK, Console, Outros serviços AWS
        pode colocar logs no CloudWatch ou S3 - trail pode ser para todas regiões (padrão) ou uma só
        se recurso for apagado, olhar cloud trail primeiro
        
        CloudTrail events
            management - operações performadas em recursos na sua conta aws (ex configurar segurança - IAM AttachRolePolicy, regras para routing (ec2 create subnet), log (cloudtrail createTrail)
                por padrão trails são configuradas para log de eventos de gerencia - pode separar eventos de leitura de eventos de escrita
            data - por padrão esses eventos não são logados por conta de volume alto de operações - pode separar leitura e escrita
                ex s3 object level activity, aws lambda function execution activity
            Insisght - detectar atividade incomum - ex buracos em manutenção periodica, limite de seviços, surtos de ações IAM, recursos indevidos provisionados
                cloudtrail analisa eventos de gerencia para criar baseline e inferir o q sai do comum
                evento eventbridge é gerado, anomalias aparecem no console do cloudtrail, armazena no s3
                
        Event Retention
            90 dias por padrão - para mais tempo, mandar p s3 e usar athena para analisar eles
            
        Integração EventBridge - interceptar chamadas de API
        
    AWS Config
        auditoria, compliance de recursos - versiona configurações
        ex mudanças de ALB por tempo, se tem acesso irrestrito ssh a grupos de segurança, se buckets tem acesso publico - pode receber alerta via SNS p cada mudança
        por região - pode agregar dados em uma região - armazena no s3, pode usar athena p analisar
        
        pode usar regras managed (75 delas) ou custom - regras podem ser avaliadas ou disparadas p cada mudança de config ou a cada intervalo de tempo
        não previne ações de serem executadas (não tem deny) - só visualização
        não tem de graça, 0.003 centavos de dolar por item guardado por região, 0.001 centavos de dolar por regra de avaliação por região
        
        mostra recurso por tempo (compliance, config) - pode ligar com cloud trail
        Remediations - SSM automation document - não nega, mas pode agir em cima de casos que disparam regras - tem retry
            ex revogar acesso IAM de usuario inativo - usuario chega a ser inativo, não previne isso, mas remedia tirando acesso
        Notifications - disparar evento em event bridge de itens não compliants
                
IAM Avançado
    Organizações - Organizations
        global - gerencia multiplas contas (dividias em conta gerente e conta membro - membros só podem ser parte de uma organização)
        consolida cobrança entre todas as contas em um metodo de pagamento unico - beneficia de uso agregado (disconto de alto uso sobre s3, EC2...)
        instancias reservadas e planos de economia compartilhados através das contas
        
        Organization Unit - OU -> management accounts -> sub ous (dev, qa, product, etc) - pode organisar por negocio, por ambiente, por projeto...
        
        segurança melhor multi conta melhor q uma conta multi vpc
        tag para cobrança - cloudtrail em todas as contas mandando para s3 da conta central - roles multiconta para administração de contas
        Security Control Policies (SCP) - politicas IAM aplicas para oU ou contas para restringir usuarios e roles
            não se aplicam a conta management (poder total) - precisam ter allow explicito - não permitem nada por padrão assim como IAM)
            lembrar que deny sobrepoe allow
        
        pode ter OU dentro de OU
    
    Politicas Avançadas
        IAM conditions - bloco condition com condições (NotIpAddress, StringEquals
            aws:sourceIp, aws:RequestRegion, ec2:ResourceTag, aws:MultiFactorAuthPresent
        IAM para s3 - arn:aws:s3:::test - permissão a nivel de bucket
        Resource Policies & awsPrincipalOrgID - só contas membros da organização        
        
    Politicas baseadas em recurso Vs Roles IAM
        cross account: resource policy para recurso ou usar role como proxy
            usuario de role larga permissões originais e assumem da role - quando usa politica baseada em recurso não
    
    Policy Evaluation Logic
        Permission Boundaries
            suportado para usuarios e roles, NÃO grupos - recurso avançado para usar uma politica gerenciada para dizer qul o máximo de permissões que uma entidade IAM pode ter
                se permissão der acesso a algo fora do limite (boundary), não adianta pq não vai poder ter
            pode ser usado em combinação com SCP de organizações na aws - permissões serão intersecção entre permissão IAM propria, SCP e permission boundary
        
        ordem: deny - SCP - resource based - identity based - IAM boundaries - session - (se não tem allow é deny implicito) - deny sobrepoe allow
            
    IAM Identity Center
        sucessor do AWS single sign on (SSO) - para contas AWS de uma organização, apps cloud (salesforce, box, microsoft 365... ) - tem q ter SAML 2.0 habilitado - instancias EC2 windows
        identity providers - identity store de IAM identity center ou terceiro (active directory (AD), oneLogin, Okta...)
            permission sets (coleção de IAM policies para usuarios e grupos que definem acessos)
                no identity center define quais usuarios acessam o que - granularidade em acesso a td inclusive multi contas
                app assignemnt - provem acesso a apps com SAML 2.0, provem urls, certificados e metadados
                attribute based access control (ABAC) - granulariza permissões de acordo com atributos de usuarios salvos no IAM identity center identity store
                    define acesso uma vez, modifica acesso via modificar atributos        
        
    Directory Services
        Active Directory - AD - todos windows server tem - banco de dados de objetos como usuario, contas, computadores, impressoras, compartilhamentos, grupos de segurança
            centralização de gerencia de segurança, criar contas, dar permissões - objetos organizados em arvores, arvores em florestas
        AWS managed microsoft AD - cria AD na aws, gerencia usuarios de forma local, suporta MFA - estabelece "conexões de confiança" com AD on premise
        AD connector - proxy para redirecionar para AD - usuaris gerenciados no AD on premise
        Simple AD - compativel com AD, gerenciado na AWS - não pode ser juntado(joined) com AD on premise
        
        identity center: AD setup
            conectar com aws managed AD - OOTB
            conectar com diretorio autogerenciado - criar criar two way trust relationship com AD gerenciado na AWS
        
    Control Tower
        simplificação de configurar e gerenciar ambiente multi conta aws seguro e compliante em melhores praticas
        usa aws organizations para criar contas - melhores praticas - autmatiza config em poucos cliques - detecta violação de politica - monitora compliance através de dashboard
        
        guardrails - governança constante para ambiente control tower
            preventive - usa SCP
            detective - usa aws config

AWS Security & Encryption
    Encriptação
        Encriptação em transito/voo
            dados encriptados antes de enviar e decriptados depois de receber - tls ajuda (https) - encriptação garante defesa contra homem no meio (Man in the middle, MITM)
        Server side encryption at rest
            dados encriptados depois de recebidos, decriptados antes de enviar - guarda encriptado por uma chave - chaves precisam ser gerenciadas fora do servidor, mas servidor precisa de acesso
        client side
            dados encriptados e decriptados no cliente - servidor não decripta - pode usar encriptação de envelope
            
    AWS KMS (Key Management Service) - antes era KMS customer master key
        maioria dos serviços aws - gerencia chaves - integrado com IAM - audita todas chamadas para usar chaves no cloudtrail
        pode ser usado transparentemente por quase todos serviços aws - nunca armazenar dados secretos em texto ou no codigo
        usavel via api (sdk, cli) - segredos encriptados podem ser guardados no codigo ou variaveis de ambiente
        
        pode ser simetrico (chaves AES-256) - uma chave usada p decriptar e encriptar - serviços aws q usam kms são simetricos nesse aspecto - 
            nunca ter acesso a chave decriptada - forçar chamada a api KMS p usar
        assimetrico - chave publica encripta e chave privada decripta - usado tb p assinar e verificar documentos digitais - chave publica é compartilhada
            chave privada não é acessivel sem encriptação - usar fora de aws quando não conseguirem chamar KMS
            
        tipos de chave - aws owned (livre, costuma ser coisa do tipo sse-s3, sse-sqs) e aws gerenciada (costuma ser coisa do tipo aws/nome-servico)
            chaves no kms gerenciadas - 1 dolar por mes por chave
            chaves no kms importadas (só aceita simetrica) 1 dolar por mes por chave - paga por chamadas a api do kms (3 centavos por 10000 chamadas)
            
        rotação automatica
            aws gerenciada - automatica todo ano
            gerenciada por usuario - precisa ser habilitado, auto todo ano
            importada - só manual, usando alias
            
        copia snapshots - cruza regiões
            cria snapshot, enc. por sua propria chave kms gerenciada por customer - dar politica com acesso cross conta - dividir snapshot enc. - cria copia do snapshot encritpa com cmk na sua conta
            cria volume do snapshot
        
        politica de chaves - controla acesso a chaves, similar a s3 - diferença é não dá p controlar acesso sem no kms
            politica padrão - criada se não criar uma - acesso total a chave para usuario root - acesso total a conta aws inteira
            politica personalizada - define usuarios, roles q podem acessar chave - define quem pode administrar chave - util para acesso cross-account a chave kms
            
        chaves multi região
            recomendado evitar
            chaves kms identicas em regiões distintas que podem ser usadas intercambiavelmente - mesmo id, material, rotação automatica...
            encripta em uma região e decripta nas outras - não precisa reencriptar ou fazer chamadas cross-região a api
            não é global (primario + replicas) - cada "região" de uma chave multiregião é gerenciada de forma independente - 
                usado para client side global enc., enc. no dynamo global e no aurora global
            
            uso com dynamo global e global aurora
                pode encriptar atributos especificos client side - usando amazon dynamodb encryption client ou aws enc. sdk (aurora)
                combinado com tabelas globais recplica dados enc. p outras regiões - se usar chave replicada, latencia para chamadas api kms caem
                usando client side pode garantir proteção de certos campos e exigir que só decripte com acesso a chave via api
                
        replicação s3 e encriptação
            objetos sem enc. são replicados por padrão - com chave sse-c(chave de usuario) podem ser replicados
            objetos com sse-kms precisa de habilitar opção - adaptar politica kms para chave alvo - dar iam role com kms:decrypt para chave fonte e encrypt para chave alvo
                se der erro de throtle pedir aumento de service quotas
            pode usar chave multiregião mas vão ser decriptados e reencriptados por serem consideradas independentes
            
        encriptação ami e compartilhamento
            ami na conta fonte é enc. usando kms da conta fonte - modificar atributo de imagem para adicionar permissão launch q corresponde a conta alvo
            - diviidr chaves usadas p encriptar snapshot de ami p conta e iam role alvo - iam/role/usuario precisam ter permissões describeKey, ReEncrypted, CreateGrant, Decrypt - 
            - quando executar conta alvo pode especificar nova chave kms p reencriptar volumes
        
    SSM Parameter store
        armazenamento seguro p config e secrets - enc. transparente usando kms - serverless, escalavel, duravel, sdk simples - versionamento de secrets/config
        segurança através de IAM - notificações com event bridge - integração com cloudformation
        
        hiearquia
            /my-dep/
                myapp/
                    dev/
                        db-url,db-password <---- GetParameters ou GetParametersByPath -----< (Lambda)
        pode usar variaveis de referencia (id de secret no kms por ex.) - pode usar variaveis globais estaticas (ex /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2
        
        tiers
            padrão - 10000 parametros por conta e região - 4kb de tamanho - não tem politicas - não tem custo adicional - armazenar gratis
            avançado - 100000 parametros conta região - 8kb - tem politicas - cobra - 5 centavos de dolar por parametro avançado por mes
            
        politicas (tier avançado)
            TTL para parametro (forçar deleção/atualização de dados sensiveis) - multiplas politicas ao mesmo tempo
            pode ter eventos de expiração (por timestamp), notificação de expiração e sem mudanças (por tempo) no event bridge
            
        *aws ssm get-parameter --names [NAMES] --with-decryption
            
    AWS Secrets Manager
        força rotação de secrets a cada x dias - automatiza geração de segredos na rotação usando lambda - integra com rds - enc. com kms
        segredos multiregião - possivel replicar p outras regiões - mantem replicas de leitura sincronizadas com original - pode promover replica para standalone
    
    AWS Certificate Manager
        provisiona, gerencia e deploy de cert. TLS - enc. em transito para sites https - suporta TLS publico e privado - gratis para cert. TLS publico
        renovação automatica de cert. tls - integra(carrega os certs. em ) com load balancers (CLB, ALB, NLB), cloudfront, api gateway
        não é usavel com EC2 (não extrai)
        
        request de cert. publicos
            1 - listar nomes de dominios p incluir (nome qualificado, pode ter wildcard *)
            2 - escolher metodo de validação: dns (preferir por ser automatico, precisa de registro CNAME) ou email(envia emails para contato no banco WHOIS)
            3 - espera horas para verificar
            4 - certificado é emitido e colocado para renovar automatico 60 dias antes de expiração
            
        importar cert. publico externo
            sem renovação automatica, importar novo antes de atual expirar - ACM envia eventos de expiração diarios (padrão 45 dias antes)
            é possivel usar aws config para verificar se cert. externos vão expirar - cert. ficam não compliant
            
        API Gateway - tipos de endpoint
            edge optmized (padrão) - clientes globais - req. roteados por locais cloudfront edge (latencia melhor) - api gateway fica em uma região só
            regional - clientes na mesma região - pode combinar manualmente com cloudfront p controle de cache e distribuição
            private - só no mesmo VPC usando interface VPC endpoint - usa politica de recurso para definir acesso
            
            p integrar tem q criar custom domain name no gateway
                edge - cert. tls tem q tá na mesma região q cloudfront, precisa de cnmae ou A-ALias no route 53
                regional - cert. tls tem q ser importado no gateway na mesma região que API Stage - CNAME A-Alias no route 53
    
    Web App FireWall (WAF)
        protege de exploits na camada 7 (HTTP) - deploy em ALB, api gateway, cloudfront, appsync graphql API, cognito user pool
        definir regras de access control list (ACL) 
            - IP set (atpe 10000 ips, usar multiplas regras p mais ips)
            - readers http, body http ou uri protegem contra ataques comuns (XSS e Sql injection)
            - limites de tamanho, geo-match (bloquear países)
            - regras de taxas (contar ocorrencia de eventos ) para proteger contra DDoS
        ACL é regional exceto para cloudfront - grupo de regras é um conjunto de regras reusavel p adicionar a web ACL

        ex ip fixo com waf no load balancer - não suporta nlb
            global accelareator p ip fixo para waf ai waf no alb
    
    Shield (DDoS)
        requests ao mesmo tempo para travar maquinas - shield é de graça - prorege contra SYN/UDP Floods, Reflection e outros ataques em layer 3/ layer 4 
        Shield acançado - mitigação DDoS opcional contra mais sofisticados ataques - 3k usd por empresa por mes
            protege em ec2, elb, cloudfront, global accelerator, route 53 - da acesso a time de resposta ddos da aws 24/7
            protege dos surtos de custos causados por DDoS - cria regras automaticas waf para mitigar ataques camada 7
    
    FireWall Manager
        gerencia regras em todas as contas de uma organização aws
        politica de segurança - conjunto de regras de segurança (shield, waf, ec2, ALB, ENI de VPC, firewall VPC, route53 resolver dns firewall)
            politica a nivel de região e aplicada a todos recursos criados por todas contas e futuras contas da organização
        
        waf, firewall manager e shield são usados juntos
            waf - mais proteção granular, onde define ACL
            waf em multiplas contas - firewall manager com waf
    
    DDoS - melhores praticas
        edge location mitigation (bp1, bp3) - bp1: best pratice 1
            cloudfront - web app delivery na fronteira
            global accelerator - acessar na fronteira
            bp3 - route53
            
        resiliencia
            defesa de infra bp1, bp3, bp6 - usar global accelerator, elb, cloud front, asg(bp7) protege de trafego
            
        app layer defense
            filtra conteudo malicioso - waf, cloudfront, shield advanced
        
        attack surface (bp1, bp4, bp6) - esconder quem atende requisição
            cloudfront, api gateway, ELB protegem lambda e ec2 - elastic ip protegido por shield advanced, nacl (netwaork ACLs)
            
        proteção de endpoints - api gateway, cloudfront edge
            
    GuardDuty
        intelligent threat discovery p proteger conta usando ML - 30 dias trial - não precisa instalar nada
        analiza logs de cloudtrail, s3 data events, vpc flow logs, dns logs, eks, rds aurora ebs...
        pode ter eventbridge para notificar automaticamente detecção de anomalias e mandar p sns e sqs e lambda - bom p proteger de ataques criptos, pois é treinado p isso
    
    Inspector
        automatiza verificações de segurança em instancias em EXECUÇÃO apenas - acessa banco de dados de vulnerabilidades - continuo - dá score e relatorio do q arrumar
        ec2 - usa agente SSM - analisa acesso rede não intencional, OS contra vulnerabilidades
        ecs - faz push da imagem p analise
        lambda - vulnerabilidades em codigo e dependencias - verifica no deploy
        integra com eventbridge
    
    Macie
        gerenciado q usa ML e pattern matching para proteger dados sensiveis - alerta se achar dados desses nos s3 e poe no event bridge
    

Networking - VPC - Virtual Private Cloud
    CIDR - IPV4
        class inter-domain routing - metodo de alocar end. ip - usado em regras de segurança e rede aws
        intervalo de ip - 192.168.0.0/26 - do final zero ao final 63 (64 endereços)
        
        componentes - ip base: um ip no intervalo - subnet mask: quantos bits podem mudar no ip (/0,/24,/32)
            /8 - 255.0.0.9, /16 = 255.255.0.0, /24 - 255.255.255.0, /32 - 255.255.255.255
            numero de ips q pode mudar = expoente é 32 - mascara (ex /31 -> 32 - 31 = 1)
            
        Ip publico e privado (IPv4)
            ips privados só permitem valores 10.0.0.0/8 (redes grandes), 172.16.0.0/12 (padrão aws vpc fica nesse intervalo), 192.168.0.0/16 (redes "domesticas)
            todo resto é publico
            
    VPC padrão
        criada com contas novas - novos ec2 sobem nele se não especifica subnet - tem conexão com internet e todas instancias ec2 dentro tem ip publico ipv4
        também tem nomes publico e privado de dns
        
    VPC
        pode ter até 5 por região (pode aumentar) - 5 CIDR por região, tamanho minimo é /28, maximo é /16, só intervalos privados ipv4 são permitidos
        garantir que CIDR da vpc não tenha intersecção com outras redes suas - se não não dá p conectar direito
        tenacy - se hardware é próprio ou compartilhado
        Vpc pode conter subnets publicas e privadas
        
    Subnets
        aws reserva primeiros 4 (.0 endereço de rede, .1 reservado p router vpc, .2 reservado para dns aws, .3 reservado p uso futuro) e ultimo(.255 broadcast) endereço em cada subnet
            aws não suporta broadcast em vpc então reserva p não tentarem usar

    Internet Gateway (IGW)
        permite q recursos numa pvc se conectem a internet - escala horizontalmente e é disponivel e redundante - precisa ser criado separado da vpc
        sozinhos não dão acesso a internet - precisa editar route tables (internet - IGW - router (route table) - security group(ec2))
        
    Bastion Hosts
        acessar ec2 em subnet privada de subnet publica (tudo no mesmo vpc) - ssh p bastion, de bastion ssh p ec2 privado
        ec2 em subnet publica com grupo de segurança tem acesso ssh a instancia na subnet privada - bastion é a subnet publica q conecta nas privadas
        precisa permitir porta 22 de CIDR restritos (CIDR publico de empresa por ex) - grupo de segurança dos ec2 precisa permitir o grupo de segurança do bastion (ip privado do bastion)
        
    NAT Instances
        defasados, preferir nat gateways - permite ec2 em redes privdas a conectar na internet - precisa ser rodado em subnet publica
        desabilitar config ec2 source / destination check
        precisa de ip elastico - tabelas de routeamento precisam ser configuradas para rotear trafego de subnet privada a instancia nat
        tem ami linux preconfigurada, mas não tem mais suporte de 31 dez 2020 - não tem disponibilidade alta, resilicencia, config OOTB - precisa de ASG, scripts, não é multiAZ por padrão
        precisa gerenciar grupos de seg. e regras - trafego depende de tipo de ec2
            inbound - permitir http, https, ssh de subnet privadas - outbound - tragego http, https p internet

    NAT Gateway
        gerenciado por aws, maior banda, disponibilidade, sem admin., sem necessidade de grupos de segurança 
        paga por hora de uso e banda - é criado em um AZ especifico, usa ip elastico
        não pode ser usado por instancia ec2 na mesma subnet, só de fora dela - precisa de IGW (subnet -> nat gw -> igw)
        5 gbps de banda com escala automatica até 100 gbps
        alta disponibilidade - resiliente em az unico, mas precisa criar multiplos em multiplos az para tolerancia a falhas - não tem cross az pq se az cai não precisa de nat
        não dá p usar como bastion
        
    Security Groups & NACLs (Network Access Control List)
        opera a nivel de subnet (security group opera a nivel de instancia)
    
        NACL é stateless | (inbound request) request -> NACL -->subnet --->security groups -->instance | se passa p dentro, é permitido sair não importa as regras
        Security group é stateful | (outbound) ec2 --> security group ---> nacl ---> internet | nacl p voltar sempre é consultado pq é stateless
        
        como se fosse firewall, um disso por subnet, novas subnets ganham nacl default - regras são definidas por usuario
        priorioadade numeros menores mais prioritairo - primeira regra obedecida define decisão - ultima regra é * e é deny por padrão
        nacl novo nega tudo - bom jeito de bloquear acesso ip de dentro da subnet
        
        nacl padrão - aceita tudo in/out na subnet q é associado - não modificar, criar proprio

        portas efemeras (só vivem durante conexão)
            qqr endpoint q criam conexão precisam usar portas - clientes conectam em uma porta definida e esperam resposta numa porta efemera
            OS diferentes tem intervalos de portas diferentes   
    
    VPC Peering
        conectar duas vpcs de forma privada usando rede da aws - as duas se comportam como se estivessem na mesma rede - não pode ter CIDR comum aos dois
        todos vpcs precisam ter vpc peering habilitado - não é transitivo (se a e b se conectam e b e c se conectam, precisa habilitar para a e c tb)
        tem q habilitar tabelas de roteamento em cada Subnet de VPC para garantir comunicação
        pode ser cross account e cross region - pode referenciar grupos de segurança de outras vpcs pareadas
    
    VPC Endpoints
        instancias podem ir direto pela rede AWS (privada) para serviços aws para evitar rede publica (internet) - menor latencia e menor custo
        todo serviço aws é publico - vpc endpoint usam privatelink para conectar usando rede privada - redundantes e escalam horizontalmente
            evitam necessidade de IGW, NATGW etc para acesso a serviços aws
        em caso de problemas, verificar resolução de DNS na vpc, route tables
        
        tipos
            Interface Endpoints (private Link)
                ENI (ip privado) (precisa de grupo de segurança - suporta maioria dos serviços - paga por hora por giga
            Gateway Endpoints
                provisiona gateway e precisa ser usado como alvo de route table (não usa grupo de segurança) - suporta s3 e dynamodb apenas - gratis
        
        para s3, preferir gateway (só mudar routetable). usar interface SÓ se precisar de acesso on premises, outra vpc ou outra região        
    
    VPC Flow Logs
        info de trafego em ip p interfaces (vpc flow logs, subnet flow logs, ENI flow logs) - monitoria e suporte problemas de conectividade
        pode mandar logs para s3, cloudwatch, kinesis data firehose
        captura informações de interfaces gerenciadas AWS - ELB, RDS, ElastiCache, Redshift, WorkSpaces, NATGW, Transit Gateway
        
        srcaddr & dstaddr - source & destination addresses - identificar IPs problematicos
        action - sucesso ou falha por conta de sec group / NACL
        pode usar athena no s3 ou CW logs Insights
        
        fluxo de uso
            olhar action - inbound reject - pode ser NACL ou sec.group. inbound accept, outbound reject - NACL
                outbound reject - NACL ou sec.group - outbound accept, inbound reject - NACL
    
    Site to Site VPN, Virtual Private Gateway, Customer Gateway
        conecta vpc a rede privada de empresa
        Virtual private gateway (VGW) - vpc concentrator lado aws da conexão vpn - criado a  partir da vpc - pode mudar Autonomous SYstem Number
        Customer Gateway (CGW) - app ou dispositivo no lado cliente da conexão
        
        CGW precisa de ip publico com acesso a internet - se tá atrás de NAT com NAT-T habilitado, usar ip publico do NAT - precisa habilitar route propagation na route table associada a subnets
            se precisar pingar ec2 de onpremises, habilitar protocolo ICMP no inbound do sec. group
            
        CloudHub
            comunicação segura entre multiplos sites se tiver multiplans conexões vpn - custo baixo - é VPN logo usa internet (publico) - para configurar, usar multiplas VPN no mesmo VGW
                habilitar dynamic routing, configurar route tables
            
    Direct Connect (DX) & Direct Connect Gateway
        conexão privada deidcada de rede remota a vpc - entre DataCenter e local AWS direct connection - precisa de VGW no vpc - acerssa recursos publicos (S3) e privados (Ec2) na mesma conexão
        aumentar banda, trabalhar com datasets grandes, abaixar custo, consistencia, ambiente hibridos (cloud+premises)
        
        conexões dedicadas: 1gbps, 10 e 100 - ethernet fisico no consumidor - request feito p aws primeiro e completado por parceiros
        conexões hospedadas: 50 mb/s, 500, 10 gbp/s - requests p parceiros aws direct connect - capacidade adicionada ou removida sob demanda - 1 2 5 10 gbps para select dx partners
        
        lead time maior que 1 mes p estabelecer novas conexões
        sem enc. - para ter enc. precisa de vpn p ter ipsec connection - mais seguro, mais complexo
    
    Direct Connect + Site to Site VPN
        se dx falhar, pode ter um dx backup (caro) ou site-site vpn    
    
    Transit Gateway
        vcp peering transitivo entre milhares de vpc, premises, conexões hub-and-spoke (star) - regional, pode ser cross usando Resource Access Manager (RAM)
        pode pper transit gateway cross region - route tables limitam qual vpc fala com qual vpc - funciona com Direct Connect Gateway, VPN
        SUPORTA MULTICAST DE IP (UNICO SERVIÇO AWS Q FAZ ISSO)
        
        ECMP - equal cost multipath - estrategia de routeamento q escolhe melhor caminho entre multiplos - criar multiplos site to site vpn para aumentar banda da conexão
    
    VPC Traffic Mirroring
        capturar e inspecionar trafego na vpc - rotear trafego para aplicações de segurança - caputra trafegos de ENI e para ENI ou NLB
        captura pacotes (todos ou filtro), podendo truncar - origem e destino podem ser na mesma vpc ou outras vpc usando peering
        usado em monitoria
    
    Ipv6 for VPC
        ipv4 tem 4.3 bi endereços possíveis que logo vão expirar - ivp6 provem numero 3.4 x 10 ^ 38
        todos ipv6 na internet são publicos e roteaveis (sem intervalo privado) - formato x.x.x.x.x.x.x.x (x é hex intervalo de 0000 a ffff)
        ex: 2001:db8:3333:4444:5555:6666:7777:8888, :: (tudo zero), ::1234:5678 (primeiros 6 segmentos zero), 2001:db8::1234:5678(4 do meio são zero)
        
        Ipv6 em VPCs
            Ipv5 não pode ser desabilitado em VPC e subnets - pode habilitar IPV6 p operar em modo dual-stack - Ec2 vão ter ip interno privado ipv4 e ip publico ipv6
            podem conectar na internet usando ipv4 ou ipv6 usando IGW
        
        se não conseguir por EC2 na subnet pode ser falta de ipv4, criar nova CIDR ipv4 na subnet
        
    Egress Only Internet Gateway
        só ipv6 (similar a nat gateway mas só p ipv6) - permite conexões ipv6 de saida prevenindo internet de conectar com instancias
        precisa atualizar route tables
    
    Networking Costs - por GB
        trafego no mesmo az com ip privado - gratis
        trafego com ip publico entre az - 2 centavos por gb
        trafego com ip privado entre az - 1 centavos por gb
        trafego inter região - 2 centavos por gb
        
        s3 ingress - gratiz
        s3 internet - 9 centavos por gb
        s3 transfer acceleration - soma 4 a 8 centavos por gb
        s3 p cloudfront - gratiz
        cloudfront internet - 8,5 centavos (mais barato q s3 com latencia menore cache) - pode sair até 7x mais barato
        s3 cross region replication - 2 centavos por gb        
        
        NAT GW - 4,5 centavos por hora, por dado processado /gb        
        ip privado é mais barato - usar mesma az para economizar (ao custo de disponibilidade) - tentar manter maximo de trafego DENTRO da aws p minimizar custos        
    
    Network Firewall
        protege vpc com firewall - layer 3 a layer 7 - vpc a vpc, internet vpc, vpc internet, dx e site to site
        internalmente usa AWS Gateway Load Balancer (GWLB)- regras podem ser gerenciadas centralmente por AWS Firewall Manager p usar em multiplos VPC
        suporta milhares de regras - fltros por ip, porta, protocolo, dominio, pattern matching, pode permitir, negar ou ter alerta das regras
        active flow inspection - igual GWLB mas gerenciado por AWS - proteção contra invasão - logs pode mandar p s3, cloudwatch logs, kinesis data firehose

DR & Migrations

    DR pode ser on-premise - on-premise (tradicional sem cloud, caro), on-premise - aws (hibrido), aws - aws (região A p região B)
    RPO - recovery point objective (pontos de restauração) - tempo entre RPO e desastre é dados perdidos
    RTO - recovery time objectiove - tempo entre desatre e recuperação (downtime)
    
    quanto menor RTO e RPO maior custo
    
    estrategias (RTO diminui da primeira p quarta)
        backup e restore
            tempo alto, por conta de snapshots, tiers de s3, restabelecer instancias ec2 usando AMI            
        pilot light
            versão lite sempre rodando, o resto similar a backup e restore mas menor pois um pedaço tá rodando (seja por replicação continua)
            usa route53 p redirecionar p versão lite
        warm standby
            sistema completo sempre rodando com "menor capacidade" - usa replicação p ter uma replica quente e usa failover p escalar reserva e pegar dados de replica            
        hotsite/multisite
            sistema reserva completo sempre rodando em AWS e onpremise, só usa route 53 (roda ativo ativo por padrão)
            failover em multi região só redireciona p região funcionando
            
    backup - EBS Snapshots, s3(IA, glacier), s3 lifecycle policy, cross region replication, (on premises - snowball ou storage gateway)
    disponibilidade - route53, RDS multiAZ, elasticache multiAZ, EFS, s3, direct connect, site to site vpn            
    replicacação - RDS replication (Cross Region), Aurora + Global DB, replicação premises p RDS, storage gateway
    automação - cloudformation, elastic beanstalk, recuperar com cloudwatch alarms, lambda
    chaos - usado por netflix - alguem vai desligando aplicações em produção p testar infra
    
    DataBase Migration Service (DMS)
        resiliente e autocurante - origem fica disponivel durente migração - suporta migração homogenea (oracle oracle ex) e heterogenea (SQL server - aurora ex)
        migração continua usando CDC - precisa de instancia EC2 p fazer tarefas de migração
        
        fontes: on premises e instancias EC2 de bancos de dados, azure, RDS, s3, document Db
        destinos: on premises e instancias EC2 de bancos de dados, RDS, kafka, redis, babelfish, dynamo, etc
        
        se não tiver no mesmo engine, usar schema conversion tool (SCT) - não precisa usar se usar mesmo engine (ex onprem postgres p rds postgres)
        replicação continua, multi az (replica sync em outro AZ)
        
    Migração para RDS e Aurora
        snapshot de rds e restaurar como aurora db OU replica de leitura aurora do RDS e quando for consistente promover p cluster (mais demorado e caro)
        se for externo, usar dump ou xtrabackup p gerar dump e mandar p s3
            usar DMS se os dois serviços estiverem em execução
        
    Onpremise strategy com AWS
        download iso de amazon linux 2 -> usar ambiente virtual tipo vmware, virtual box etc
        vm import export -> migra vm para ec2 diretamente
        aws app discovery service - pega info de server on premise p planejar migração (AWS MIgration Hub)
        Server Migration Service (SMS) - migração gradativa de on premise p aws
        
    AWS backup
        gerenciado - automatiza backup de serviços AWS - sem scripts, hub central
        s3, rds, efs, fsx, storage gateway...
        cria politicas,tags (frquencia, janela, transição para cold storage, retenção)
        vault lock - WORM (escreve 1 vez, le muito) - nem root consegue apagar
        
    Application Discovery Service (MGN)
        planeja migração - descobre dependencias e utilização
        agentless disocvery (discovery connector) - configuração, especificações de VM
        agent based discovery (discovery agent) - processos, rede, conexões
        lift and shift - converte onpremises para rodar em aws
        
    Transferir dados enormes p AWS
        ex 200tb
        internet, site site vpn - 185 dias
        direct connect - 1 mes p ter conexão, mais 18 dias
        snowball - 3 em paralelo, 1 semana
        para replicação constante, DMS, Dx, dataSync, site to site vpn
        
    VMWare cloud na AWS
        p usar vmware cloud p gerenciar data center on premises e conseguir usar aws, tem vmware cloud on aws

More Solution Architectures
    Event Processing
        SQS + Lambda (se tiver loop infinito, mandar mensagem para uma fila "morta" após n tentativas) (try, retry,, try, retry, blocking)
        SNS + Lambda (lambda retenta 3 vezes internamente, sem chamar sns - mandar falhas para SQS)
        é possivel reagir a notificações de eventos S3 e mandar para lambda, sns, sqs ou event bridge que manda p muitas outras coisas e pode filtrar
        event bridge pode interceptar chamadas a api aws integrando com cloudtrail
        
    Cache
        TTL para renovar cache e pegar coisas atualizadas do backend - balancear cache na fronteira com cache na aplicação
        latencia e tempo computacional aumentam na linha usuario - app - db
        
    Bloquear Ip na AWS
        NACL pode bloquear acesso na vpc, security group não pode, mas pode dar allow só nos que quer
        ALB pode usar connection termination (ALB mata conexão de fora e abre p dentro) - só garantir q grupos de segurança permitem os acessos
        WAF pode filtrar Ips, mas é mais caro
        
        uma boa arquitetura seria client - cloudfront - VPC(secgroup(public ALB) - secgroup(Ec2))
                                               |
                                               WAF
    
    High Performance Computing (HPC)
        nuvem é ambiente ideal p HPC - criar alto numero de recursos em pouco tempo - paga só pelo q usa
        
        Data Mgmt & Transfer - Direct Connect, Snowball & Snowmobille, DataSync com agent
        Compute & Network - Ec2 (Spot, fleets, ASG, Placement Groups Cluster), Ec2 Enhanced Network (SRIOV), Elastic Fabric Adapter (EFA)
        Storage - EBS, Instance Store, S3, EFS, Fsx for Lustre
        Automation & Orchestration - Aws Batch, Aws ParallelCluster com EFA
    
    Ec2 Instance High Availability
        Ec2 com ip elastico, ASG, EBS
        
        
Outros Serviços
    CloudFormation
        forma declarativa de instaciar recursos - cloud formation cria na ordem exata com a config especificada
        infra as code (não cria manual) - parece yaml, mas tem json tb - recursos são tageados e fica mais facil estimar e ver custos
        pode automatizar tarefas por ambiente por hora
        pode recriar e destruir infra na hora, gera diagramas automaticos para templates, programação declarativa (não precisa pensar em ordenação ou orquestração)
        existe mts templates na web e mta documentação - suporta quase todos recursos AWS, os que não suporta, pode usar recurso customizado
        
        Cloud formation pode ser vizualisado no app. composer - mostra recursos e relacionamento entre eles
        detecta mudanças e aplica mudanças
        
        Service Role
            role IAM que permite que cloudformation efetue operações crud em stack de recursos - dá habilidade a usuarios efetuarem essas operações mesmo sem as permissões usando a role
            util para principio do menor privilegio - usario precisa ter permissão iam:PassRole
        
    SES
        Simple Email Service - gerenciado - manda email seguro, global, escalavel
        pode receber resposta, tem performance, estatisticas, se é spam, se foi aberto, ip flexivel, acessivel do console, api, e SMTP
        suporta DKIM e SPF
    
    Pinpoint
        SMS envio/recebimento (suporta email, voz, e mensagens de app tb) - pode personalizar e segmentar mensagems, escala p bilhão por dia, recebe resposta
        no SNS e SES vc precisa gerenciar agenda, conteudo, e publico, no pinpoint isso é automatizado via segmentação, templates e agendas
        
    SSM Session Manager (SSM é systems manager)
        secure shell em ec2 e premises sem ssh, bastion - não precisa da porta 22 (maior segurança) - linux, macos, windows
        logs de sessão para s3 ou cloudwatch - usado através do systems manager
        
        run command - roda script ou comando bash em multiploas instancias usando resource groups, não precisa de ssh
            output é mostrado no console, pode mandar p s3 ou cloudwatch ou sns(status da execução) - integrado com IAM e cloudtrail, pode ser chamado usando event bridge
        
        patch manager - automatiza patchs (ec2 e premises) - pode ter janelas de manutenção - pode escanear e gerar relatório
            console, sdk, maintenance window
        automation - simplifica manutentção e tarefas de deploy de ec2 e outros recursos aws - usa runbook para gerar ações
            sobe instancias, cria snapshot, cria AMI
        
    Cost Explorer
        visualizar custos e uso AWS por tempo - relatorios, etc, granular - ajuda escolher planos - tem serviço de previsão de custos
    
    Cost Anomaly Detection
        monitora usando Machine Learning p detectar pontos fora da curva, e aumentos continuos - funciona sem configurar
        notifica usando sns - manda relatorio com analise de causa raiz
        
    AWS Batch
        gerenciado, roda em qqr escala - centenas de milhares de jobs na aws (Batch é serviço com inico e fim)
        executa ec2 ou spot dinamicamente p atender serviço - só agendar serviço e batch faz o resto
        imagens docker q rodam no ecs
        otimização de custo sem focar em infra
        
        diferenças com lambda
            batch - sem limite de tempo, roda qtas vezes quiser como docker image, usa ebs/ instance store como armazenamento, usa ec2 (gerenciado por aws)
            lambda - limite de tempo, limite de vezes executado, pouco espaço de armazenagem, serverless
        
    AppFlow
        transferencia de dados de SaaS e aws - fontes salesforce, sap, zendesk, slack, service now
            destinos - s3, redshift, snowflake, salesforce
        agendamento, resposta a evento ou sob demanda - enc. na internet ou privatelink - pode transformar, filtrar e validar dados durante transferencia
        
        mais facil q fazer o etl por conta
        
    Amplify
        ferramentas p desenvolver e deploy de apps full stack web e mobile escalaveis
        lida com auth, storage, api (rest, graphql) ci/cd, pubsub, analytics, AI/ML
        conecta com codigo de github, aws codecommit, bitbucket, gitlab ou pode fazer upload direto


Whitepaper and Architectures
    well architected framework and tool
        não tentar adivinhar necessidade de capacity - usar ASG
        testar em escala de produção
        automatizar p experimentos mais facil - cloudformation
        pensar em arquitetura evolutiva
        pensar em dados na arquitetura
        iterar em game days (simular datas criticas)
        
        1 - operacional excelente
        2 - segurança
        3 - confiança
        4 - performatico
        5 - otimização de custo
        6 - sustentabilidade
        
        esses 6 são sinergicos, não opcionais entre um e outro
        
        tool - perguntas baseadas nos 6 pilares q geram conselhos
    
    trusted advisor
        leitura de alto nivel de conta - não precisa instalar nada
        para ter todas as analises, precisa ter plano business ou enterprise - tem acesso programatico usando api de suporte aws
        
    mais ex de arquitetura
        https://aws.amazon.com/architecture
        https://aws.amazon.com/solutions    

------------------------

AZ - availability zone
NAT - network Address Translation
DNS - Domain Name System
    The Domain Name System (DNS) is the phonebook of the Internet. Humans access information online through domain names, like nytimes.com or espn.com. 
    Web browsers interact through Internet Protocol (IP) addresses. DNS translates domain names to IP addresses so browsers can load Internet resources.
IOPS - IO Operations per second
PIOPS - provisioned IOPS
KMS - AWS Key Management Service - facilita a criação e o controle de chaves criptográficas usadas para proteger os dados.
POSIX (Interface de Sistema Operacional Portátil para UNIX) é um conjunto de padrões para interfaces e especificações que suportam portabilidade e compatibilidade entre sistemas semelhantes ao UNIX. 
    O padrão define várias funções, como manipulação de arquivos, gerenciamento de processos e chamada do sistema APIs.
Whitelist (allowlist) is a cybersecurity strategy that approves a list of email addresses, IP addresses, domain names or applications, while denying all others.
Important ports:
    FTP: 21
    SSH: 22
    SFTP: 22 (same as SSH)
    HTTP: 80
    HTTPS: 443
    vs RDS Databases ports:
    PostgreSQL: 5432
    MySQL: 3306
    Oracle RDS: 1521
    MSSQL Server: 1433
    MariaDB: 3306 (same as MySQL)
    Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)
    TTL - time to live
DR - disaster recovery
Ingress expõe rotas HTTP e HTTPS de fora do cluster para um serviço dentro do cluster. O roteamento do tráfego é controlado por regras definidas no recurso Ingress.
ACL - access control list
LDAP é um protocolo padrão que fornece meios de armazenar e recuperar informações sobre pessoas, grupos ou objetos em um servidor de diretórios X. 500 ou LDAP centralizado.

CRUD - Create Read Update Delete
ETL - extract transform load
SAML(Security Assertion Markup Language) 
    possibilita a tecnologia de logon único (SSO) ao fornecer uma maneira de autenticar um usuário uma única vez e, em seguida, comunicar essa autenticação a vários aplicativos.
STS - security token service    
OLTP - online transacion processing
OLAP - online analytical process
OOTB - out of the box
ASR - automated speech recognition
CRM - customer relationship management
NLP - processamento de linguagem natural
ML - machine learning
SaaS - software as a Service
K8s - Kubernetes
SSM - AWS Simple System Manager - agora chama AWS Systems Manager
SSO - single sign on
DDoS - Em um ataque distribuído de negação de serviço (DDoS), um tipo de ataque cibernético, um invasor sobrecarrega um website, servidor ou recurso de rede com tráfego malicioso. 
    Como resultado, o alvo trava ou não consegue operar, negando serviço a usuários legítimos e impedindo que o tráfego legítimo chegue ao seu destino.
NAT - Em redes de computadores, Network Address Translation (NAT), também conhecido como masquerading, é uma técnica que consiste em reescrever, utilizando-se de uma tabela hash, 
    os endereços IP de origem de um pacote que passam por um router ou firewall de maneira que um computador de uma rede interna tenha acesso ao exterior ou Rede Mundial de Computadores.[1]
NACL - Network Access Control List (NACL). A NACL is a security layer for your VPC, that acts as a firewall for controlling traffic in and out

Camadas de transporte da internet OSI
    Camada 1 - Física
    Camada 2 - Enlace ou Ligação - controla o fluxo com que os pacotes são enviados.
        VLans, ou topologias como a Token ring, ou a ponto-a-ponto. Também é nela que dispositivos como os switches funcionam.
        Esta camada é dividida em duas subcamadas: A camada MAC e a camada LLC.
            MAC - conexão de diversos computadores em uma rede. Cada máquina conectada na rede tem um endereço físico, conhecido como endereço MAC.
                interface entre a camada física e a subcamada LLC.
            LLC - controle de fluxo dos dados - permite vários protocolos da próxima camada na mesma rede
    Camada 3 - Rede - IP de origem e de destino e priorização e rota - protocolo IP, ICMP...
    Camada 4 - Transporte - garante o envio e o recebimento dos pacotes vindos da camada 3 - TCP, UDP...
    Camada 5 - Sessão - estabelecer e encerrar a conexão entre hosts
    Camada 6 - Apresentação - tradução dos dados para que a próxima camada os use - criptografia
    Camada 7 - Aplicação - consumir os dados, HTTP, FTP, além de serviços como o DNS.
    
CDC - replicação ou captura continua de dados de alteração
Machine Learning vs Deep Learning - machine learning é mais generalista e mais supervisionado
https://github.com/aws-cloudformation/aws-cloudformation-templates
DKIM - DomanKeys Identified Mail
SPF - Sender Policy Framework
SaaS - sofware as a service

https://www.udemy.com/certificate/UC-c4aae2e8-9262-40f9-8888-35d2961003ad/?utm_campaign=email&utm_medium=email&utm_source=sendgrid.com
